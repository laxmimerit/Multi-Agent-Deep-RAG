{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Financial Research Agent with Hybrid Search\n",
    "Build an intelligent agent that can search financial documents (RAG) and live market data to provide comprehensive insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook covers:\n",
    "- **Hybrid Search (RAG)**: Semantic + keyword search with automatic filter extraction from historical SEC filings\n",
    "- **Live Finance Research**: Real-time stock data and market information via Yahoo Finance MCP\n",
    "- **Agent with Dual Tools**: Connect LLM agent with both vector database and live APIs\n",
    "- **Financial Analysis**: Query historical SEC filings (10-K, 10-Q) and current market data\n",
    "- **Metadata Filtering**: Automatic extraction of company, year, quarter from queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from langchain.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "from scripts.rag_tools import hybrid_search\n",
    "from scripts.prompts import MULTIMODEL_AGENT_PROMPT\n",
    "\n",
    "# Initialize the model\n",
    "# You can use any available model at google ai studio\n",
    "model = ChatGoogleGenerativeAI(model='gemini-3-flash-preview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Live Finance Research Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "@tool\n",
    "def live_finance_researcher(query: str) -> str:\n",
    "    \"\"\"Research live stock data using Yahoo Finance MCP.\n",
    "    \n",
    "    Use this tool to get:\n",
    "    - Current stock prices and real-time market data\n",
    "    - Latest financial news\n",
    "    - Stock recommendations and analyst ratings\n",
    "    - Option chains and expiration dates\n",
    "    - Recent stock actions (splits, dividends)\n",
    "    \n",
    "    Args:\n",
    "        query: The financial research question about current market data\n",
    "        \n",
    "    Returns:\n",
    "        Research results from Yahoo Finance\n",
    "    \"\"\"\n",
    "    code = f\"\"\"\n",
    "import asyncio\n",
    "from scripts.yahoo_mcp import finance_research\n",
    "asyncio.run(finance_research(\"{query}\"))\n",
    "\"\"\"\n",
    "    result = subprocess.run([sys.executable, '-c', code], capture_output=True, text=True)\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Financial Research Agent with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent():\n",
    "    conn = sqlite3.connect(\"data/financial_rag_agent.db\", check_same_thread=False)\n",
    "    checkpointer = SqliteSaver(conn=conn)\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=model,\n",
    "        tools=[hybrid_search, live_finance_researcher],\n",
    "        system_prompt=MULTIMODEL_AGENT_PROMPT,\n",
    "        checkpointer=checkpointer\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "agent = get_agent()\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {'messages': [HumanMessage(\"What is Apples's cash flow in 2023?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response\n",
    "# print(response['messages'][-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_agent_response(agent, query, thread_id=\"default\"):\n",
    "\n",
    "    config = {'configurable': {'thread_id': thread_id}}\n",
    "    \n",
    "    for chunk in agent.stream(\n",
    "        {'messages': [HumanMessage(query)]},\n",
    "        stream_mode='messages',\n",
    "        config=config\n",
    "    ):\n",
    "        # Extract message from chunk\n",
    "        message = chunk[0] if isinstance(chunk, tuple) else chunk\n",
    "        \n",
    "        # Handle AI messages with tool calls\n",
    "        if isinstance(message, AIMessage) and message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                print(f\"\\n  Tool Called: {tool_call['name']}\")\n",
    "                print(f\"   Args: {tool_call['args']}\")\n",
    "                print()\n",
    "        \n",
    "        # Handle tool responses\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"\\n  Tool Result (length: {len(message.text)} chars)\")\n",
    "            print()\n",
    "        \n",
    "        # Handle AI text responses\n",
    "        elif isinstance(message, AIMessage) and message.text:\n",
    "            # Stream the text content\n",
    "            print(message.text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_agent_response(agent, \"What was Amazon's revenue in Q1 2024?\", thread_id=\"session_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_agent_response(agent, \"What is the current stock price of Apple (AAPL) and show me latest news?\", thread_id=\"session_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_agent_response(agent, \"Compare Microsoft's Q2 2024 revenue from filings with its current stock performance\", thread_id=\"session_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_agent_response(agent, \"Compare Google's revenue between Q1 2024 and Q1 2023\", thread_id=\"session_4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
