{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG - Data Ingestion Pipeline\n",
    "### Load Extracted Data into Qdrant with Multimodal Embeddings\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Load extracted markdown, tables, and images from 06-01\n",
    "- Create hybrid embeddings (dense + sparse)\n",
    "- Store in Qdrant with rich metadata\n",
    "- Support multimodal search (text + images)\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run 06-01 notebook first to extract PDFs into markdown/images/tables\n",
    "- Qdrant server running on localhost:6333\n",
    "\n",
    "**What This Notebook Does:**\n",
    "1. Load markdown files (split by page breaks)\n",
    "2. Load tables with context\n",
    "3. Load images with multimodal embeddings\n",
    "4. Store all in single Qdrant collection with content_type metadata\n",
    "5. Enable hybrid retrieval with deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "MARKDOWN_DIR = \"data/rag-data/rag-markdown\"\n",
    "TABLES_DIR = \"data/rag-data/rag-tables\"\n",
    "IMAGES_DIR = \"data/rag-data/rag-images\"\n",
    "\n",
    "# Qdrant Configuration\n",
    "COLLECTION_NAME = \"financial_docs\"\n",
    "EMBEDDING_MODEL = \"multimodalembedding@001\"  # Vertex AI Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Embeddings and Vector Store\n",
    "\n",
    "**Hybrid Retrieval**: Combines dense (semantic) and sparse (keyword) search for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal embeddings (Vertex AI) - works for text AND images\n",
    "embeddings = VertexAIEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "# Sparse embeddings (BM25)\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# Initialize vector store with hybrid retrieval\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=[],\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    url=\"http://localhost:6333\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    force_recreate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract metadata from markdown filename.\n",
    "    \n",
    "    Expected format: {company} {doc_type} {quarter} {year}.md\n",
    "    Examples:\n",
    "    - amazon 10-k 2024.md\n",
    "    - amazon 10-q q1 2024.md\n",
    "    \n",
    "    Returns:\n",
    "        dict with company_name, doc_type, fiscal_year, fiscal_quarter\n",
    "    \"\"\"\n",
    "    name = filename.replace('.md', '')\n",
    "    parts = name.split()\n",
    "    \n",
    "    metadata = {}\n",
    "    metadata['company_name'] = parts[0]\n",
    "    metadata['doc_type'] = parts[1]\n",
    "    \n",
    "    if len(parts) == 4:\n",
    "        metadata['fiscal_quarter'] = parts[2]\n",
    "        metadata['fiscal_year'] = int(parts[3])\n",
    "    else:\n",
    "        metadata['fiscal_quarter'] = None\n",
    "        metadata['fiscal_year'] = int(parts[2])\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "def compute_file_hash(file_path: str) -> str:\n",
    "    \"\"\"Compute SHA-256 hash of file content for deduplication.\"\"\"\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Processed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get already processed files from Qdrant\n",
    "all_points = vector_store.client.scroll(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    limit=10000,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "processed_hashes = set(\n",
    "    point.payload.get('file_hash') \n",
    "    for point in all_points[0] \n",
    "    if point.payload.get('file_hash')\n",
    ")\n",
    "\n",
    "print(f\"Already processed: {len(processed_hashes)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_markdown_to_vectordb(md_path: Path):\n",
    "    \"\"\"Ingest markdown file into Qdrant vector store.\"\"\"\n",
    "    print(f\"Processing: {md_path.name}\")\n",
    "    \n",
    "    file_hash = compute_file_hash(md_path)\n",
    "    if file_hash in processed_hashes:\n",
    "        print(f\"  [SKIP] Already processed\")\n",
    "        return\n",
    "    \n",
    "    # Read markdown content\n",
    "    markdown_text = md_path.read_text(encoding='utf-8')\n",
    "    \n",
    "    # Split by page breaks\n",
    "    page_break = \"<!-- page break -->\"\n",
    "    pages = markdown_text.split(page_break)\n",
    "    \n",
    "    # Get metadata from filename\n",
    "    file_metadata = extract_metadata_from_filename(md_path.name)\n",
    "    \n",
    "    documents = []\n",
    "    for page_num, page_text in enumerate(pages, start=1):\n",
    "        if page_text.strip():\n",
    "            metadata = file_metadata.copy()\n",
    "            metadata['content_type'] = 'text'\n",
    "            metadata['page'] = page_num\n",
    "            metadata['file_hash'] = file_hash\n",
    "            metadata['source_file'] = md_path.name\n",
    "            \n",
    "            doc = Document(page_content=page_text.strip(), metadata=metadata)\n",
    "            documents.append(doc)\n",
    "    \n",
    "    vector_store.add_documents(documents=documents)\n",
    "    processed_hashes.add(file_hash)\n",
    "    \n",
    "    print(f\"  [DONE] Ingested {len(documents)} pages\")\n",
    "\n",
    "\n",
    "def ingest_tables_to_vectordb(company_dir: Path):\n",
    "    \"\"\"Ingest table files into Qdrant vector store.\"\"\"\n",
    "    table_count = 0\n",
    "    for doc_dir in company_dir.iterdir():\n",
    "        if doc_dir.is_dir():\n",
    "            for table_file in doc_dir.glob(\"table_*.md\"):\n",
    "                file_hash = compute_file_hash(table_file)\n",
    "                if file_hash in processed_hashes:\n",
    "                    continue\n",
    "                \n",
    "                # Read table content\n",
    "                table_content = table_file.read_text(encoding='utf-8')\n",
    "                \n",
    "                # Extract metadata from parent directory name\n",
    "                doc_name = doc_dir.name\n",
    "                file_metadata = extract_metadata_from_filename(doc_name + '.md')\n",
    "                \n",
    "                # Extract table number\n",
    "                table_num = int(table_file.stem.split('_')[1])\n",
    "                \n",
    "                metadata = file_metadata.copy()\n",
    "                metadata['content_type'] = 'table'\n",
    "                metadata['table_number'] = table_num\n",
    "                metadata['file_hash'] = file_hash\n",
    "                metadata['source_file'] = table_file.name\n",
    "                \n",
    "                doc = Document(page_content=table_content, metadata=metadata)\n",
    "                vector_store.add_documents([doc])\n",
    "                processed_hashes.add(file_hash)\n",
    "                table_count += 1\n",
    "    \n",
    "    if table_count > 0:\n",
    "        print(f\"  [DONE] Ingested {table_count} tables\")\n",
    "\n",
    "\n",
    "def ingest_images_to_vectordb(company_dir: Path):\n",
    "    \"\"\"Ingest images with multimodal embeddings into Qdrant vector store.\"\"\"\n",
    "    image_count = 0\n",
    "    for doc_dir in company_dir.iterdir():\n",
    "        if doc_dir.is_dir():\n",
    "            for image_file in doc_dir.glob(\"page_*.png\"):\n",
    "                file_hash = compute_file_hash(image_file)\n",
    "                if file_hash in processed_hashes:\n",
    "                    continue\n",
    "                \n",
    "                # Extract page number from filename\n",
    "                page_num = int(image_file.stem.split('_')[1])\n",
    "                \n",
    "                # Extract metadata from parent directory name\n",
    "                doc_name = doc_dir.name\n",
    "                file_metadata = extract_metadata_from_filename(doc_name + '.md')\n",
    "                \n",
    "                metadata = file_metadata.copy()\n",
    "                metadata['content_type'] = 'image'\n",
    "                metadata['page'] = page_num\n",
    "                metadata['image_path'] = str(image_file)\n",
    "                metadata['file_hash'] = file_hash\n",
    "                \n",
    "                # Embed image directly using multimodal embeddings\n",
    "                image_embedding = embeddings.embed_image(uri=str(image_file))\n",
    "                \n",
    "                # Create document with image embedding\n",
    "                doc = Document(\n",
    "                    page_content=f\"Visual content from page {page_num}\",\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                # Add with custom embedding\n",
    "                vector_store.add_embeddings([(doc, image_embedding)])\n",
    "                processed_hashes.add(file_hash)\n",
    "                image_count += 1\n",
    "    \n",
    "    if image_count > 0:\n",
    "        print(f\"  [DONE] Ingested {image_count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process markdown files\n",
    "print(\"=== Ingesting Markdown Files ===\")\n",
    "markdown_path = Path(MARKDOWN_DIR)\n",
    "md_files = list(markdown_path.rglob(\"*.md\"))\n",
    "print(f\"Found {len(md_files)} markdown files\\n\")\n",
    "\n",
    "for md_path in md_files:\n",
    "    ingest_markdown_to_vectordb(md_path)\n",
    "\n",
    "# Process tables\n",
    "print(\"\\n=== Ingesting Tables ===\")\n",
    "tables_path = Path(TABLES_DIR)\n",
    "for company_dir in tables_path.iterdir():\n",
    "    if company_dir.is_dir():\n",
    "        print(f\"Processing {company_dir.name}...\")\n",
    "        ingest_tables_to_vectordb(company_dir)\n",
    "\n",
    "# Process images\n",
    "print(\"\\n=== Ingesting Images ===\")\n",
    "images_path = Path(IMAGES_DIR)\n",
    "for company_dir in images_path.iterdir():\n",
    "    if company_dir.is_dir():\n",
    "        print(f\"Processing {company_dir.name}...\")\n",
    "        ingest_images_to_vectordb(company_dir)\n",
    "\n",
    "print(\"\\n[ALL DONE]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = vector_store.client.get_collection(COLLECTION_NAME)\n",
    "print(f\"Total documents in Qdrant: {collection_info.points_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hybrid search\n",
    "query = \"What is Amazon's revenue?\"\n",
    "results = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. Type: {doc.metadata.get('content_type')} | Page: {doc.metadata.get('page')}\")\n",
    "    print(f\"   Company: {doc.metadata.get('company_name')} | Year: {doc.metadata.get('fiscal_year')}\")\n",
    "    print(f\"   Content: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
