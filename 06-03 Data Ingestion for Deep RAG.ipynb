{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion for Deep RAG\n",
    "\n",
    "In this notebook, we'll load extracted data into Qdrant vector database:\n",
    "\n",
    "- **Markdown**: Page-level chunks with metadata\n",
    "- **Tables**: Separate documents with context and page numbers\n",
    "- **Images**: Text descriptions embedded (generated in notebook 06-01b)\n",
    "- **Hybrid Search**: Dense (semantic) + Sparse (keyword) embeddings\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run notebook 06-01 first to extract PDFs\n",
    "- Run notebook 06-01b to generate image descriptions\n",
    "- Qdrant server running on localhost:6333\n",
    "- Google API key set in .env file\n",
    "\n",
    "**Output:**\n",
    "- Single Qdrant collection with all content types\n",
    "- Rich metadata for filtering (company, year, quarter, doc_type, page)\n",
    "- Deduplication using file hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Sure You Have Your QDRANT Vector DB Docker Running**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qdrant.tech/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\n",
    "from langchain_core.documents import Document\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "MARKDOWN_DIR = \"data/rag-data/markdown\"\n",
    "TABLES_DIR = \"data/rag-data/tables\"\n",
    "IMAGES_DESC_DIR = \"data/rag-data/images_desc\"\n",
    "\n",
    "# Qdrant Configuration\n",
    "COLLECTION_NAME = \"financial_docs\"\n",
    "EMBEDDING_MODEL = \"models/gemini-embedding-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize Embeddings and Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create or Recreate Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=[],  # Empty initialization\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=\"http://localhost:6333\",\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    force_recreate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store._client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse from 06-01\n",
    "def extract_metadata_from_filename(filename: str):\n",
    "    \"\"\"Extract metadata from filename.\"\"\"\n",
    "    \n",
    "    filename = filename.replace('.pdf', '').replace('.md', '')\n",
    "    parts = filename.split()\n",
    "\n",
    "    return {\n",
    "        'company_name': parts[0],\n",
    "        'doc_type': parts[1],\n",
    "        'fiscal_quarter': parts[2] if len(parts)==4 else None,\n",
    "        'fiscal_year': parts[-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_file_hash(file_path: Path) -> str:\n",
    "    \"\"\"Compute SHA-256 hash for deduplication.\"\"\"\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points = vector_store.client.scroll(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        limit=10000,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "all_points[0][0].payload['metadata']['file_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_hashes():\n",
    "    \"\"\"Get all file hashes from Qdrant.\"\"\"\n",
    "    \n",
    "    processed_hashes = set()\n",
    "    offset = None\n",
    "    \n",
    "    while True:\n",
    "        points, offset = vector_store.client.scroll(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            limit=10000,\n",
    "            offset=offset,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        if not points:\n",
    "            break\n",
    "            \n",
    "        processed_hashes.update(\n",
    "            point.payload['metadata'].get('file_hash') \n",
    "            for point in points\n",
    "        )\n",
    "        \n",
    "        if offset is None:\n",
    "            break\n",
    "    \n",
    "    return processed_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_hashes = get_processed_hashes()\n",
    "len(processed_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_page_number(file_path: Path) -> int | None:\n",
    "    \"\"\"Extract page number from filename (e.g., table_1_page_5.md -> 5).\"\"\"\n",
    "    match = re.search(r'_page_(\\d+)', file_path.stem)\n",
    "    return int(match.group(1)) if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ingestion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_file(file_path: Path, processed_hashes: set):\n",
    "    \"\"\"Ingest markdown files (text, tables, images) into vector store.\"\"\"\n",
    "\n",
    "    # Skip if already processed\n",
    "    file_hash = compute_file_hash(file_path)\n",
    "    if file_hash in processed_hashes:\n",
    "        return\n",
    "\n",
    "    # Determine content type and document name from path\n",
    "    path_str = str(file_path)\n",
    "    if 'markdown' in path_str:\n",
    "        content_type = 'text'\n",
    "        doc_name = file_path.name\n",
    "    elif 'tables' in path_str:\n",
    "        content_type = 'table'\n",
    "        doc_name = file_path.parent.name\n",
    "    elif 'images_desc' in path_str:\n",
    "        content_type = 'image'\n",
    "        doc_name = file_path.parent.name\n",
    "    else:\n",
    "        return  # Skip unknown types\n",
    "\n",
    "    # Read content\n",
    "    content = file_path.read_text(encoding='utf-8')\n",
    "\n",
    "    # Build base metadata\n",
    "    base_metadata = extract_metadata_from_filename(doc_name)\n",
    "    base_metadata.update({\n",
    "        'content_type': content_type,\n",
    "        'file_hash': file_hash,\n",
    "        'source_file': file_path.name\n",
    "    })\n",
    "\n",
    "    # Create and add documents based on content type\n",
    "    if content_type == 'text':\n",
    "        # Split markdown by page breaks\n",
    "        pages = content.split(\"<!-- page break -->\")\n",
    "        documents = [\n",
    "            Document(page_content=page_text.strip(), metadata={**base_metadata, 'page': i})\n",
    "            for i, page_text in enumerate(pages, start=1)\n",
    "            if page_text.strip()\n",
    "        ]\n",
    "        vector_store.add_documents(documents)\n",
    "\n",
    "    else:  # table or image\n",
    "        page_num = extract_page_number(file_path)\n",
    "        metadata = {**base_metadata, 'page': page_num} if page_num else base_metadata\n",
    "        vector_store.add_documents([Document(page_content=content, metadata=metadata)])\n",
    "\n",
    "    processed_hashes.add(file_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Ingest All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all markdown files from all directories\n",
    "base_path = Path(\"data/rag-data\")\n",
    "all_md_files = list(base_path.rglob(\"*.md\"))\n",
    "\n",
    "# Ingest everything with single function\n",
    "for md_file in all_md_files:\n",
    "    ingest_file(md_file, processed_hashes)\n",
    "\n",
    "print(\"All data ingested successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Verify Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = vector_store.client.get_collection(COLLECTION_NAME)\n",
    "collection_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hybrid search\n",
    "query = \"What is Amazon's revenue?\"\n",
    "results = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
