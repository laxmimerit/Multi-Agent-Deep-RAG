{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ln6kjqqbye",
   "metadata": {},
   "source": [
    "# Gemini 3 with LangChain - Complete Guide\n",
    "\n",
    "This notebook demonstrates all key features of Google's Gemini 3 model family using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xa68ee9qixc",
   "metadata": {},
   "source": [
    "## Gemini 3 Overview\n",
    "\n",
    "**Gemini 3 Pro** is Google's most intelligent model family, built on state-of-the-art reasoning capabilities.\n",
    "\n",
    "### Key Features\n",
    "- **Advanced Reasoning**: Dynamic thinking process with configurable thinking levels\n",
    "- **1M Token Context**: Up to 1 million token input, 64k token output\n",
    "- **Multimodal Excellence**: Images, PDFs, audio, video with granular resolution control\n",
    "- **Knowledge Cutoff**: January 2025\n",
    "- **Image Generation**: 4K resolution with grounded generation\n",
    "\n",
    "### Model Variants\n",
    "\n",
    "| Model | Context (In/Out) | Best For |\n",
    "|-------|------------------|----------|\n",
    "| `gemini-3-pro-preview` | 1M / 64k | Complex reasoning, coding, analysis |\n",
    "| `gemini-3-pro-image-preview` | 65k / 32k | Image generation & editing |\n",
    "| `gemini-2.5-flash` | 1M / 8k | Fast, cost-effective tasks |\n",
    "\n",
    "### New Features in Gemini 3\n",
    "1. **Thinking Level**: Control reasoning depth (`low` or `high`)\n",
    "2. **Media Resolution**: Granular control per media type (`low`, `medium`, `high`, `ultra_high`)\n",
    "3. **Temperature**: Keep at default 1.0 (changing can cause degraded performance)\n",
    "4. **Thought Signatures**: Automatic reasoning context preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irht2ya07js",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load environment variables for API authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfd6ca",
   "metadata": {},
   "source": [
    "https://ai.google.dev/gemini-api/docs/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d084daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d016",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Demonstrates basic message formats and response structures for both Gemini 3 and 2.5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9290cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini3 = \"gemini-3-pro-preview\"\n",
    "# gemini2 = \"gemini-2.5-pro\"\n",
    "gemini2 = \"gemini-2.5-flash\"\n",
    "\n",
    "system_msg = SystemMessage(\"You are a helpful assistant.\")\n",
    "\n",
    "query = \"Explain the theory of relativity in simple terms.\"\n",
    "messages = [system_msg, HumanMessage(query)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a704462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini3)\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b339a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content\n",
    "response.content_blocks\n",
    "response.usage_metadata\n",
    "response.response_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42834e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "jup3y8bmko",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Stream tokens in real-time as they're generated, improving user experience for long responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zv8hfcnycet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "\n",
    "query = \"Write a short story about the earth and the moon.\"\n",
    "for chunk in model.stream(query):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qwbn2z2ouk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b25696ed",
   "metadata": {},
   "source": [
    "## Multimodal Capabilities\n",
    "\n",
    "Process images, PDFs, audio, and video alongside text. Gemini 3 supports multiple input modalities with granular resolution control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34622026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini3)\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Describe the image provided.\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"url\": \"https://www.shutterstock.com/image-vector/vector-cute-baby-panda-cartoon-600nw-2427356853.jpg\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bok3gc83l4",
   "metadata": {},
   "source": [
    "### Image Analysis from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29121303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading media from local file and encoding to base64\n",
    "## Now use smaller model for faster response\n",
    "\n",
    "## image mime type example\n",
    "# mime_type = \"image/png\"\n",
    "\n",
    "## pdf mime type example\n",
    "# mime_type = \"application/pdf\", type = \"file\"\n",
    "\n",
    "## audio mime type example\n",
    "# mime_type = \"audio/mpeg\", type = \"audio\"\n",
    "\n",
    "import base64\n",
    "\n",
    "image_bytes = open(\"data/images/panda.png\", \"rb\").read()\n",
    "bytes_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "mime_type = \"image/png\"\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Describe the image provided.\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"base64\": bytes_base64,\n",
    "            \"mime_type\": mime_type,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "response = model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dx5bhkhgjju",
   "metadata": {},
   "source": [
    "### Image Analysis from Local File\n",
    "\n",
    "Base64 encode local images, PDFs, or audio files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7uds2msor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_bytes = open(\"data/rag-data/apple/apple 10-q q1 2024.pdf\", \"rb\").read()\n",
    "pdf_base64 = base64.b64encode(pdf_bytes).decode(\"utf-8\")\n",
    "\n",
    "mime_type = \"application/pdf\"\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Summarize the key financial highlights from this quarterly report.\"},\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"base64\": pdf_base64,\n",
    "            \"mime_type\": mime_type,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2y71k0tx3gr",
   "metadata": {},
   "source": [
    "### PDF Document Analysis\n",
    "\n",
    "Extract and analyze content from PDF files. Recommended to use `media_resolution_medium` for PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jgnk8voi9p",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v606zv7oap",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content\n",
    "response.content_blocks\n",
    "response.usage_metadata\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cf266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65dafee8",
   "metadata": {},
   "source": [
    "## Tool Calling (Function Calling)\n",
    "\n",
    "Bind custom tools to the model for extended capabilities like web search or API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first show ollama web_search tool\n",
    "# then build weather tool\n",
    "\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = base_tools.web_search.invoke({'query': 'what is the latest US stock market updates?'})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = base_tools.get_weather.invoke({'location': 'Mumbai'})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "model_with_tools = model.bind_tools([base_tools.web_search, base_tools.get_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools\n",
    "response = model_with_tools.invoke(\"what is the weather in Mumbai today? and latest news on US stock market?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f330ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8a8ad",
   "metadata": {},
   "source": [
    "## Thinking Support (Reasoning)\n",
    "\n",
    "Configure the model's reasoning depth with `thinking_budget` or `thinking_level`. \n",
    "\n",
    "**Gemini 3 Recommendation**: Use `thinking_level=\"high\"` (default) for complex tasks, `\"low\"` for simple tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe5fb5",
   "metadata": {},
   "source": [
    "**Documentation**: https://ai.google.dev/gemini-api/docs/thinking\n",
    "\n",
    "Control reasoning depth:\n",
    "- `thinking_budget`: Legacy parameter (number of tokens)\n",
    "- `thinking_level`: New parameter (`\"low\"` or `\"high\"`)\n",
    "- `include_thoughts`: Show reasoning process in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini2,\n",
    "                               thinking_budget=1024,\n",
    "                               include_thoughts=True)\n",
    "\n",
    "query = \"explain the theory of relativity in simple terms.\"\n",
    "response = model.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd50e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)\n",
    "# print(response.text)\n",
    "\n",
    "response.content_blocks\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b68f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools([base_tools.web_search, base_tools.get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content_blocks\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e81169",
   "metadata": {},
   "source": [
    "## Built-in Tools\n",
    "\n",
    "Google Gemini provides native tools: Google Search and Code Execution. These require no additional setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b8605",
   "metadata": {},
   "source": [
    "Google Gemini supports a variety of built-in tools, which can be bound to the model in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "\n",
    "#  base_tools.get_weather -> function calling with tool use is unsupported.\n",
    "model_with_tools = model.bind_tools([{\"google_search\": {}}, {\"code_execution\": {}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca213e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When is the next total solar eclipse in the US and what is 3 + 2?\"\n",
    "response = model_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d4b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "w28ct2tqdwm",
   "metadata": {},
   "source": [
    "## Context Caching\n",
    "\n",
    "Cache large documents to reduce costs and latency for repeated queries. Minimum 2,048 tokens required.\n",
    "\n",
    "**Benefits**:\n",
    "- Reduced API costs\n",
    "- Faster response times\n",
    "- Ideal for analyzing large documents repeatedly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eadaff3",
   "metadata": {},
   "source": [
    "**Resources**:\n",
    "- [Caching Guide](https://ai.google.dev/gemini-api/docs/caching?hl=en&lang=python#pdfs_1)\n",
    "- [Pricing Details](https://ai.google.dev/gemini-api/docs/pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5k16cgx4n7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "from google.genai.types import CreateCachedContentConfig, Content, Part\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n3776cxvaa",
   "metadata": {},
   "source": [
    "### Initialize Client and Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641plamjz7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"data/rag-data/apple/apple 10-q q1 2024.pdf\",\n",
    "    \"data/rag-data/apple/apple 10-q q2 2024.pdf\"\n",
    "]\n",
    "\n",
    "uploaded_files = []\n",
    "for path in file_paths:\n",
    "    file = client.files.upload(file=path)\n",
    "    while file.state.name == \"PROCESSING\":\n",
    "        time.sleep(2)\n",
    "        file = client.files.get(name=file.name)\n",
    "    uploaded_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u2ugc4kllbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "for f in uploaded_files:\n",
    "    part = Part.from_uri(file_uri=f.uri, mime_type=f.mime_type)\n",
    "    parts.append(part)\n",
    "\n",
    "contents = [\n",
    "    Content(\n",
    "        role=\"user\",\n",
    "        parts=parts,\n",
    "    )\n",
    "]\n",
    "\n",
    "cache = client.caches.create(\n",
    "    model=gemini2,\n",
    "    config=CreateCachedContentConfig(\n",
    "        display_name=\"Apple Q1 Q2 2024 Reports\",\n",
    "        system_instruction=\"You are a financial analyst. Use these Apple quarterly reports to answer questions.\",\n",
    "        contents=contents,\n",
    "        ttl=\"1800s\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqoeidu4cnk",
   "metadata": {},
   "source": [
    "### Create Cache\n",
    "\n",
    "Cache content for 300 seconds (5 minutes) with system instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85h1ghe7k6i",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=gemini2,\n",
    "    cached_content=cache.name,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Compare the revenue growth between Q1 and Q2 2024.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jxziaacdlyh",
   "metadata": {},
   "source": [
    "### Query with Cached Content\n",
    "\n",
    "First query - cache is created and tokens are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4xp1igrtwwn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.text)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv1qylzxtm",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rql07yevp6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"Provide a detailed analysis of Apple's Q1 and Q2 2024 earnings with key financial metrics, revenue comparison, and growth trends. Format this as bullet points suitable for an infographic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnry1yrk0se",
   "metadata": {},
   "source": [
    "### Reuse Cache for Second Query\n",
    "\n",
    "Notice `cache_read` tokens in usage metadata - shows cache is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fmjn9pl4yv",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dv89hapoe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfatcbyr05o",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dhw48sw06no",
   "metadata": {},
   "source": [
    "## Image Generation\n",
    "\n",
    "Generate high-quality images up to 4K resolution using `gemini-3-pro-image-preview`.\n",
    "\n",
    "**Features**:\n",
    "- Text rendering in images\n",
    "- Multiple aspect ratios\n",
    "- Grounded generation with Google Search\n",
    "- Conversational editing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ae082",
   "metadata": {},
   "source": [
    "```\n",
    "# Available aspect ratios\n",
    "aspect_ratios = [\"1:1\", \"2:3\", \"3:2\", \"3:4\", \"4:3\", \"4:5\", \"5:4\", \"9:16\", \"16:9\", \"21:9\"]\n",
    "\n",
    "# Available resolutions\n",
    "resolutions = [\"1K\", \"2K\", \"4K\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87cec47",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain-google/issues/1235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ollnwdiq3n",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import Modality\n",
    "from IPython.display import Image, display\n",
    "\n",
    "aspect_ratio = \"16:9\"\n",
    "resolution = \"4K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3wnyvfglwbg",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = ChatGoogleGenerativeAI(model=\"gemini-3-pro-image-preview\")\n",
    "\n",
    "image_content = f\"Create a professional infographic with this data:\\n\\n{response.text}\"\n",
    "\n",
    "image_response = image_model.invoke(\n",
    "    image_content,\n",
    "    response_modalities=[Modality.TEXT, Modality.IMAGE],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x4p1cdyn0n",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_response.content_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_base64(response):\n",
    "    # Go through each block in the response\n",
    "    for block in response.content:\n",
    "        # Check if this block is a dictionary\n",
    "        if isinstance(block, dict):\n",
    "            # Check if it has image data\n",
    "            if \"image_url\" in block:\n",
    "                # Extract the URL\n",
    "                image_url_data = block[\"image_url\"]\n",
    "                full_url = image_url_data[\"url\"]\n",
    "                # The URL looks like: \"data:image/png;base64,ACTUALBASE64DATA\"\n",
    "                # We only want the part after the comma\n",
    "                base64_string = full_url.split(\",\")[1]\n",
    "                return base64_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hl3k4p7piyj",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = get_image_base64(image_response)\n",
    "display(Image(data=base64.b64decode(image_base64), width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ozqhmb3067p",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/images/apple_earnings_infographic.png\", \"wb\") as f:\n",
    "    f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fjoyu878lo",
   "metadata": {},
   "source": [
    "### Native Google GenAI - Advanced Image Generation\n",
    "\n",
    "LangChain doesn't fully support aspect ratio and resolution parameters yet. Use native Google GenAI SDK for full control.\n",
    "\n",
    "**Available Options**:\n",
    "- Aspect Ratios: `1:1`, `2:3`, `3:2`, `3:4`, `4:3`, `4:5`, `5:4`, `9:16`, `16:9`, `21:9`\n",
    "- Resolutions: `1K`, `2K`, `4K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2u1mezgib7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-pro-image-preview\",\n",
    "    contents=image_content,\n",
    "    config=types.GenerateContentConfig(\n",
    "        image_config=types.ImageConfig(\n",
    "            aspect_ratio=\"1:1\",\n",
    "            image_size=\"4K\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ynhaf2bk7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_parts = [part for part in response.parts if part.inline_data]\n",
    "\n",
    "image = image_parts[0].as_image()\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xxj6voih7zc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image_parts:\n",
    "    image = image_parts[0].as_image()\n",
    "    image.save('apple_earnings_square_4k.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bb551",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Force the model to return responses in a specific Pydantic schema format.\n",
    "\n",
    "**Methods**:\n",
    "- `function_calling`: Uses tool calling (default)\n",
    "- `json_schema`: Native JSON schema (more reliable for Gemini 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use weather tool for the sample structred output\n",
    "# fields -> location:str, date:str, temperature:str, condition:str\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class WeatherOutput(BaseModel):\n",
    "    location: str\n",
    "    date: str\n",
    "    temperature: str\n",
    "    condition: str\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=gemini2)\n",
    "model_with_tools = model.bind_tools([base_tools.get_weather])\n",
    "\n",
    "structured_model = model_with_tools.with_structured_output(WeatherOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = structured_model.invoke(\"what is the weather in Mumbai today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af6d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f552280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
