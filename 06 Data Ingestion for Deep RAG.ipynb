{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG - Data Ingestion Pipeline for PageRAG\n",
    "### Page-wise Document Processing with Gemini Embeddings and Qdrant\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Extract text from PDFs page by page\n",
    "- Extract metadata from filename\n",
    "- Store in Qdrant with rich metadata\n",
    "- Use Gemini embeddings\n",
    "\n",
    "**Use Cases:**\n",
    "1. Financial Analysis: Process SEC filings (10-K, 10-Q)\n",
    "2. Legal: Organize contracts and case documents\n",
    "3. Research: Index academic papers\n",
    "4. Enterprise: Searchable document repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\n",
    "from langchain_core.documents import Document\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, SparseVectorParams, SparseIndexParams\n",
    "\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"data\"\n",
    "QDRANT_PATH = \"./qdrant_financial_db\"\n",
    "COLLECTION_NAME = \"financial_docs\"\n",
    "EMBEDDING_MODEL = \"models/gemini-embedding-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Gemini Embeddings, BM25, and Qdrant\n",
    "\n",
    "**Hybrid Retrieval**: Combines dense (semantic) and sparse (keyword) search for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:20:29,225 - INFO - HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:20:29,233 - INFO - HTTP Request: GET http://localhost:6333/collections/financial_docs/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:20:29,780 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Dense embeddings (Gemini)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "# Sparse embeddings (BM25)\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# Initialize vector store with hybrid retrieval\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=[],\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    url=\"http://localhost:6333\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    force_recreate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Extraction from Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract metadata from filename.\n",
    "    \n",
    "    Expected format: {company} {doc_type} {quarter} {year}.pdf\n",
    "    Examples:\n",
    "    - amazon 10-k 2024.pdf\n",
    "    - amazon 10-q q1 2024.pdf\n",
    "    \n",
    "    Returns:\n",
    "        dict with company_name, doc_type, fiscal_year, fiscal_quarter\n",
    "    \"\"\"\n",
    "    name = filename.replace('.pdf', '')\n",
    "    parts = name.split()\n",
    "    \n",
    "    metadata = {}\n",
    "    \n",
    "    if len(parts) == 4:\n",
    "        metadata['fiscal_quarter'] = parts[2]\n",
    "        metadata['fiscal_year'] = int(parts[3])\n",
    "    else:\n",
    "        metadata['fiscal_quarter'] = None\n",
    "        metadata['fiscal_year'] = int(parts[2])\n",
    "    \n",
    "    metadata['company_name'] = parts[0]\n",
    "    metadata['doc_type'] = parts[1]\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fiscal_quarter': None,\n",
       " 'fiscal_year': 2023,\n",
       " 'company_name': 'amazon',\n",
       " 'doc_type': '10-k'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_metadata_from_filename('amazon 10-k 2023.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fiscal_quarter': 'q1',\n",
       " 'fiscal_year': 2024,\n",
       " 'company_name': 'amazon',\n",
       " 'doc_type': '10-q'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_metadata_from_filename('amazon 10-q q1 2024.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text from PDF Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_pages(pdf_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract text from each page of PDF.\n",
    "    \n",
    "    Returns:\n",
    "        List of page texts\n",
    "    \"\"\"\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(pdf_path)\n",
    "    \n",
    "    page_break = \"<!-- page break -->\"\n",
    "    markdown_text = result.document.export_to_markdown(page_break_placeholder=page_break)\n",
    "    \n",
    "    pages = markdown_text.split(page_break)\n",
    "    \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:21:55,006 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:21:55,067 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:21:55,068 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:21:55,094 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-12 14:21:55,107 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-12 14:21:55,125 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-12 14:21:55,153 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-12 14:21:56,763 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,773 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,791 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,792 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,876 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,879 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,880 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,903 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,914 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:21:56,924 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:21:57,014 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:21:57,031 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:22:21,620 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:22:21,983 - INFO - Processing document amazon 10-q q1 2024.pdf\n",
      "2025-12-12 14:22:36,742 - INFO - Finished converting document amazon 10-q q1 2024.pdf in 41.74 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 52\n"
     ]
    }
   ],
   "source": [
    "pages = extract_pdf_pages('data/rag-data/amazon/amazon 10-q q1 2024.pdf')\n",
    "print(f\"Total pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Hash for Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_file_hash(file_path: str) -> str:\n",
    "    \"\"\"Compute SHA-256 hash of file content.\"\"\"\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c08079bc14250c896f3ca151f9a72ecc1ddcb9ca8e5b021539e91af10fae5c4b'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_file_hash('data/rag-data/amazon/amazon 10-q q1 2024.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Processed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:23:05,103 - INFO - HTTP Request: POST http://localhost:6333/collections/financial_docs/points/scroll \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed: 0 files\n"
     ]
    }
   ],
   "source": [
    "# Get already processed files from Qdrant\n",
    "all_points = vector_store.client.scroll(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    limit=10000,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "processed_hashes = set(\n",
    "    point.payload.get('file_hash') \n",
    "    for point in all_points[0] \n",
    "    if point.payload.get('file_hash')\n",
    ")\n",
    "\n",
    "print(f\"Already processed: {len(processed_hashes)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_docs_in_vectordb(pdf_path: Path):\n",
    "    \"\"\"Process and ingest PDF into Qdrant vector store.\"\"\"\n",
    "    print(f\"Processing: {pdf_path.name}\")\n",
    "    \n",
    "    file_hash = compute_file_hash(pdf_path)\n",
    "    if file_hash in processed_hashes:\n",
    "        print(f\"[SKIP] Already processed: {pdf_path.name}\")\n",
    "        return\n",
    "    \n",
    "    pages = extract_pdf_pages(str(pdf_path))\n",
    "    file_metadata = extract_metadata_from_filename(pdf_path.name)\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for page_num, page_text in enumerate(pages, start=1):\n",
    "        metadata = file_metadata.copy()\n",
    "        metadata['page'] = page_num\n",
    "        metadata['file_hash'] = file_hash\n",
    "        metadata['source_file'] = pdf_path.name\n",
    "        \n",
    "        doc = Document(page_content=page_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "    \n",
    "    vector_store.add_documents(documents=documents)\n",
    "    processed_hashes.add(file_hash)\n",
    "    \n",
    "    print(f\"[DONE] Ingested {len(documents)} pages from {pdf_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 PDF files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/rag-data/amazon/amazon 10-k 2023.pdf'),\n",
       " WindowsPath('data/rag-data/amazon/amazon 10-k 2024.pdf'),\n",
       " WindowsPath('data/rag-data/amazon/amazon 10-q q1 2024.pdf')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(DATA_DIR)\n",
    "pdf_files = list(data_path.rglob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files\")\n",
    "pdf_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:23:24,218 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:23:24,220 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:23:24,221 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:23:24,221 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,231 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,234 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,234 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,276 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,277 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,278 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,301 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,306 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:23:24,307 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:23:24,371 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:23:24,372 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: amazon 10-k 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:23:25,460 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:23:25,715 - INFO - Processing document amazon 10-k 2023.pdf\n",
      "2025-12-12 14:23:56,286 - INFO - Finished converting document amazon 10-k 2023.pdf in 32.07 sec.\n",
      "2025-12-12 14:24:06,484 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:24:10,156 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:24:10,177 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:24:10,181 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:24:10,182 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:24:10,184 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,198 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,202 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,204 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,263 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,264 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,265 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,291 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,296 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:10,297 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 93 pages from amazon 10-k 2023.pdf\n",
      "Processing: amazon 10-k 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:24:10,386 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:24:10,387 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:24:11,781 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:24:12,094 - INFO - Processing document amazon 10-k 2024.pdf\n",
      "2025-12-12 14:24:44,865 - INFO - Finished converting document amazon 10-k 2024.pdf in 34.69 sec.\n",
      "2025-12-12 14:24:55,896 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:24:59,186 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:24:59,193 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:24:59,197 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:24:59,198 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:24:59,200 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,211 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,215 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,216 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,267 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,268 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,268 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,293 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,302 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:24:59,302 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 88 pages from amazon 10-k 2024.pdf\n",
      "Processing: amazon 10-q q1 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:24:59,394 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:24:59,394 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:00,694 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:00,970 - INFO - Processing document amazon 10-q q1 2024.pdf\n",
      "2025-12-12 14:25:16,255 - INFO - Finished converting document amazon 10-q q1 2024.pdf in 17.06 sec.\n",
      "2025-12-12 14:25:24,170 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:25:24,180 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:25:24,182 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:25:24,183 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:25:24,184 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,193 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,196 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,197 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,244 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,245 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,246 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,283 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,289 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:24,289 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 52 pages from amazon 10-q q1 2024.pdf\n",
      "Processing: amazon 10-q q1 2025.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:25:24,444 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:25:24,444 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:25,468 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:25,748 - INFO - Processing document amazon 10-q q1 2025.pdf\n",
      "2025-12-12 14:25:40,906 - INFO - Finished converting document amazon 10-q q1 2025.pdf in 16.73 sec.\n",
      "2025-12-12 14:25:48,642 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:25:48,653 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:25:48,654 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:25:48,655 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:25:48,655 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,666 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,669 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,670 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,712 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,714 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,715 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,738 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,743 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:25:48,744 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 50 pages from amazon 10-q q1 2025.pdf\n",
      "Processing: amazon 10-q q2 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:25:48,876 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:25:48,877 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:49,915 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:25:50,185 - INFO - Processing document amazon 10-q q2 2024.pdf\n",
      "2025-12-12 14:26:07,586 - INFO - Finished converting document amazon 10-q q2 2024.pdf in 18.93 sec.\n",
      "2025-12-12 14:26:16,180 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:26:16,202 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:26:16,204 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:26:16,205 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:26:16,205 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,217 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,220 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,221 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,263 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,264 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,265 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,310 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,316 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:16,316 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 51 pages from amazon 10-q q2 2024.pdf\n",
      "Processing: amazon 10-q q2 2025.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:26:16,458 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:26:16,460 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:26:17,518 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:26:17,777 - INFO - Processing document amazon 10-q q2 2025.pdf\n",
      "2025-12-12 14:26:35,115 - INFO - Finished converting document amazon 10-q q2 2025.pdf in 18.91 sec.\n",
      "2025-12-12 14:26:43,665 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:26:43,679 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:26:43,683 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:26:43,685 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:26:43,685 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,698 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,703 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,704 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,755 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,757 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,757 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,786 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,792 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:26:43,792 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:26:43,864 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:26:43,865 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 51 pages from amazon 10-q q2 2025.pdf\n",
      "Processing: amazon 10-q q3 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:26:44,990 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:26:45,311 - INFO - Processing document amazon 10-q q3 2024.pdf\n",
      "2025-12-12 14:27:11,385 - INFO - Finished converting document amazon 10-q q3 2024.pdf in 27.71 sec.\n",
      "2025-12-12 14:27:21,794 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:27:29,701 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:27:30,666 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:27:30,682 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:27:30,684 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:27:30,685 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:27:30,685 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,695 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,700 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,701 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,744 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,745 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,746 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,770 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,776 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:30,777 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:27:30,869 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:27:30,869 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 150 pages from amazon 10-q q3 2024.pdf\n",
      "Processing: apple 10-k 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:27:31,870 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:27:32,130 - INFO - Processing document apple 10-k 2023.pdf\n",
      "\u001b[32m[INFO] 2025-12-12 14:27:38,567 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/resources/fonts/FZYTK.TTF\u001b[0m\n",
      "\u001b[31m[ERROR] 2025-12-12 14:27:42,024 [RapidOCR] download_file.py:74: Download failed: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/resources/fonts/FZYTK.TTF\u001b[0m\n",
      "2025-12-12 14:27:42,026 - ERROR - Stage ocr failed for run 1: Failed to download https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/resources/fonts/FZYTK.TTF\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "        (self._dns_host, self.port),\n",
      "    ...<2 lines>...\n",
      "        socket_options=self.socket_options,\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\socket.py\", line 977, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "        conn,\n",
      "    ...<10 lines>...\n",
      "        **response_kw,\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "    ~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000247B849E990>: Failed to resolve 'cdn-lfs-cn-1.modelscope.cn' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "        method=request.method,\n",
      "    ...<9 lines>...\n",
      "        chunked=chunked,\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cdn-lfs-cn-1.modelscope.cn', port=443): Max retries exceeded with url: /prod/lfs-objects/40/65/a23df6823c8e2b69a0e76d02f02a6470b8774a5e91086609701ad95cc33f?filename=FZYTK.TTF&namespace=RapidAI&repository=RapidOCR&revision=v3.4.0&tag=model&auth_key=1765529859-9fa0d66a36f74c69ad3c5e4b8431861d-0-0ebff6bbbc32efeb9409e24a0007f50a (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000247B849E990>: Failed to resolve 'cdn-lfs-cn-1.modelscope.cn' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\utils\\download_file.py\", line 70, in _make_http_request\n",
      "    response = requests.get(url, stream=True, timeout=cls.REQUEST_TIMEOUT)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\sessions.py\", line 724, in send\n",
      "    history = [resp for resp in gen]\n",
      "                                ^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\sessions.py\", line 265, in resolve_redirects\n",
      "    resp = self.send(\n",
      "        req,\n",
      "    ...<6 lines>...\n",
      "        **adapter_kwargs,\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\requests\\adapters.py\", line 677, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs-cn-1.modelscope.cn', port=443): Max retries exceeded with url: /prod/lfs-objects/40/65/a23df6823c8e2b69a0e76d02f02a6470b8774a5e91086609701ad95cc33f?filename=FZYTK.TTF&namespace=RapidAI&repository=RapidOCR&revision=v3.4.0&tag=model&auth_key=1765529859-9fa0d66a36f74c69ad3c5e4b8431861d-0-0ebff6bbbc32efeb9409e24a0007f50a (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000247B849E990>: Failed to resolve 'cdn-lfs-cn-1.modelscope.cn' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py\", line 278, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\docling\\models\\auto_ocr_model.py\", line 128, in __call__\n",
      "    yield from self._engine(conv_res, page_batch)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\docling\\models\\rapid_ocr_model.py\", line 257, in __call__\n",
      "    result = self.reader(\n",
      "        im,\n",
      "    ...<2 lines>...\n",
      "        use_rec=self.options.use_rec,\n",
      "    )\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\main.py\", line 111, in __call__\n",
      "    det_res, cls_res, rec_res, cropped_img_list = self.run_ocr_steps(img, op_record)\n",
      "                                                  ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\main.py\", line 139, in run_ocr_steps\n",
      "    rec_res = self.recognize_txt(cls_img_list)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\main.py\", line 321, in recognize_txt\n",
      "    rec_res = self.text_rec(rec_input)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\ch_ppocr_rec\\main.py\", line 145, in __call__\n",
      "    viser=VisRes(lang_type=self.cfg.lang_type, font_path=self.cfg.font_path),\n",
      "          ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\utils\\vis_res.py\", line 38, in __init__\n",
      "    self.font_path = self.get_font_path(font_path, lang_type)\n",
      "                     ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\utils\\vis_res.py\", line 123, in get_font_path\n",
      "    DownloadFile.run(input_param)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\utils\\download_file.py\", line 40, in run\n",
      "    response = cls._make_http_request(input_params.file_url, logger)\n",
      "  File \"c:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\utils\\download_file.py\", line 75, in _make_http_request\n",
      "    raise DownloadFileException(f\"Failed to download {url}\") from e\n",
      "rapidocr.utils.download_file.DownloadFileException: Failed to download https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/resources/fonts/FZYTK.TTF\n",
      "2025-12-12 14:28:04,080 - INFO - Finished converting document apple 10-k 2023.pdf in 33.40 sec.\n",
      "2025-12-12 14:28:14,405 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:28:15,674 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:28:15,683 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:28:15,685 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:28:15,686 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:28:15,687 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,696 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,699 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,699 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,743 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,744 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,744 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,782 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,788 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:15,788 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 76 pages from apple 10-k 2023.pdf\n",
      "Processing: apple 10-k 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:28:15,905 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:28:15,906 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:28:16,953 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:28:17,274 - INFO - Processing document apple 10-k 2024.pdf\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:23,754 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/resources/fonts/FZYTK.TTF\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:27,048 [RapidOCR] download_file.py:82: Download size: 3.09MB\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:28:27,840 [RapidOCR] download_file.py:95: Successfully saved to: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\FZYTK.TTF\u001b[0m\n",
      "2025-12-12 14:28:54,471 - INFO - Finished converting document apple 10-k 2024.pdf in 38.79 sec.\n",
      "2025-12-12 14:29:05,745 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:29:12,275 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:29:12,285 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:29:12,287 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:29:12,288 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:29:12,288 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,299 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,302 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,303 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,350 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,352 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,352 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,389 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,395 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:12,395 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 121 pages from apple 10-k 2024.pdf\n",
      "Processing: apple 10-q q1 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:29:12,519 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:29:12,519 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:29:13,591 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:29:13,878 - INFO - Processing document apple 10-q q1 2024.pdf\n",
      "2025-12-12 14:29:24,906 - INFO - Finished converting document apple 10-q q1 2024.pdf in 12.62 sec.\n",
      "2025-12-12 14:29:28,942 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:29:28,960 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:29:28,963 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:29:28,964 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:29:28,964 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:28,973 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:28,977 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:28,978 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,034 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,035 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,036 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,058 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,064 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:29,065 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:29:29,136 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:29:29,138 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 28 pages from apple 10-q q1 2024.pdf\n",
      "Processing: apple 10-q q2 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:29:30,206 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:29:30,516 - INFO - Processing document apple 10-q q2 2024.pdf\n",
      "2025-12-12 14:29:41,857 - INFO - Finished converting document apple 10-q q2 2024.pdf in 12.90 sec.\n",
      "2025-12-12 14:29:45,962 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:29:45,980 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:29:45,981 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:29:45,982 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:29:45,982 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:45,998 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,001 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,002 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,045 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,047 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,047 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,076 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,082 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:29:46,082 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 28 pages from apple 10-q q2 2024.pdf\n",
      "Processing: apple 10-q q4 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:29:46,232 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:29:46,232 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:29:47,259 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:29:47,532 - INFO - Processing document apple 10-q q4 2023.pdf\n",
      "2025-12-12 14:29:56,602 - INFO - Finished converting document apple 10-q q4 2023.pdf in 10.62 sec.\n",
      "2025-12-12 14:30:00,151 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:30:00,169 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:30:00,171 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:30:00,171 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:30:00,172 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,183 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,188 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,189 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,240 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,242 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,243 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,267 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,273 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:00,274 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:30:00,344 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:30:00,345 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 28 pages from apple 10-q q4 2023.pdf\n",
      "Processing: apple 8-k q4 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:30:01,514 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:30:01,777 - INFO - Processing document apple 8-k q4 2023.pdf\n",
      "2025-12-12 14:30:04,769 - INFO - Finished converting document apple 8-k q4 2023.pdf in 4.60 sec.\n",
      "2025-12-12 14:30:06,259 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:30:06,270 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:30:06,274 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:30:06,275 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:30:06,276 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,285 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,288 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,289 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,340 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,341 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,342 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,366 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,371 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:30:06,372 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:30:06,472 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 9 pages from apple 8-k q4 2023.pdf\n",
      "Processing: google 10-k 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:30:06,472 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:30:07,462 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:30:07,736 - INFO - Processing document google 10-k 2023.pdf\n",
      "2025-12-12 14:30:44,705 - INFO - Finished converting document google 10-k 2023.pdf in 38.44 sec.\n",
      "2025-12-12 14:30:54,720 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:31:01,879 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:31:01,890 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:31:01,894 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:31:01,895 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:31:01,895 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,908 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,913 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,914 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,976 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,978 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:01,979 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:02,004 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:02,009 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:02,011 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-12-12 14:31:02,077 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:31:02,077 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 111 pages from google 10-k 2023.pdf\n",
      "Processing: google 10-k 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:31:03,180 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:31:03,436 - INFO - Processing document google 10-k 2024.pdf\n",
      "2025-12-12 14:31:38,813 - INFO - Finished converting document google 10-k 2024.pdf in 36.92 sec.\n",
      "2025-12-12 14:31:49,106 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:31:56,088 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:31:56,108 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:31:56,110 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:31:56,111 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:31:56,112 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,123 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,127 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,129 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,197 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,198 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,199 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,227 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,233 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:31:56,234 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 108 pages from google 10-k 2024.pdf\n",
      "Processing: google 10-q q1 2025.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:31:56,361 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:31:56,362 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:31:57,381 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:31:57,668 - INFO - Processing document google 10-q q1 2025.pdf\n",
      "2025-12-12 14:32:19,361 - INFO - Finished converting document google 10-q q1 2025.pdf in 23.25 sec.\n",
      "2025-12-12 14:32:28,432 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:32:28,446 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:32:28,447 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:32:28,448 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:32:28,449 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,461 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,465 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,466 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,520 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,522 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,523 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,552 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,559 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:32:28,559 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 52 pages from google 10-q q1 2025.pdf\n",
      "Processing: google 10-q q2 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:32:28,684 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:32:28,685 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:32:29,732 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:32:30,014 - INFO - Processing document google 10-q q2 2024.pdf\n",
      "2025-12-12 14:32:55,423 - INFO - Finished converting document google 10-q q2 2024.pdf in 26.98 sec.\n",
      "2025-12-12 14:33:05,621 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:33:05,645 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:33:05,647 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:33:05,648 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:33:05,649 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,658 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,663 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,664 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,720 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,722 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,722 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,756 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,762 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:05,763 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 55 pages from google 10-q q2 2024.pdf\n",
      "Processing: google 10-q q2 2025.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:33:05,895 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:33:05,896 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:33:06,893 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:33:07,147 - INFO - Processing document google 10-q q2 2025.pdf\n",
      "2025-12-12 14:33:36,131 - INFO - Finished converting document google 10-q q2 2025.pdf in 30.49 sec.\n",
      "2025-12-12 14:33:47,257 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-12 14:33:47,267 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-12 14:33:47,269 - INFO - Going to convert document batch...\n",
      "2025-12-12 14:33:47,269 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-12-12 14:33:47,271 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,283 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,287 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,288 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,343 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,345 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,345 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,376 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,389 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-12 14:33:47,390 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 59 pages from google 10-q q2 2025.pdf\n",
      "Processing: google 10-q q3 2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:33:47,492 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-12-12 14:33:47,493 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:33:48,552 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-12-12 14:33:48,806 - INFO - Processing document google 10-q q3 2024.pdf\n",
      "2025-12-12 14:34:12,517 - INFO - Finished converting document google 10-q q3 2024.pdf in 25.25 sec.\n",
      "2025-12-12 14:34:24,029 - INFO - HTTP Request: PUT http://localhost:6333/collections/financial_docs/points?wait=true \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Ingested 56 pages from google 10-q q3 2024.pdf\n"
     ]
    }
   ],
   "source": [
    "for pdf_path in pdf_files:\n",
    "    ingest_docs_in_vectordb(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:34:24,080 - INFO - HTTP Request: GET http://localhost:6333/collections/financial_docs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in Qdrant: 1266\n"
     ]
    }
   ],
   "source": [
    "collection_info = vector_store.client.get_collection(COLLECTION_NAME)\n",
    "print(f\"Total documents in Qdrant: {collection_info.points_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:47:46,638 - INFO - HTTP Request: POST http://localhost:6333/collections/financial_docs/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Hybrid search example (dense + sparse)\n",
    "results = vector_store.similarity_search(\n",
    "    \"What is Tesla's revenue for Q1 2024?\",\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'fiscal_quarter': 'q3', 'fiscal_year': 2024, 'company_name': 'google', 'doc_type': '10-q', 'page': 40, 'file_hash': '51ab83179bff647b1b2521836748d83939671d40a1d954fad9df93cd720e5784', 'source_file': 'google 10-q q3 2024.pdf', '_id': '0f20a018-982d-4411-84c0-6212a49f5f4e', '_collection_name': 'financial_docs'}, page_content='\\n\\nThe  following  table  presents  the  foreign  currency  exchange  effect  on  international  revenues  and  total  revenues  (in  millions,  except percentages):\\n\\n|                                    |                                  |                                  | Three Months Ended September 30, 2024   | Three Months Ended September 30, 2024   | Three Months Ended September 30, 2024   | Three Months Ended September 30, 2024   | Three Months Ended September 30, 2024   | Three Months Ended September 30, 2024   |\\n|------------------------------------|----------------------------------|----------------------------------|-----------------------------------------|-----------------------------------------|-----------------------------------------|-----------------------------------------|-----------------------------------------|-----------------------------------------|\\n|                                    |                                  |                                  |                                         |                                         | %Change from Prior Period               | %Change from Prior Period               | %Change from Prior Period               | %Change from Prior Period               |\\n|                                    | Three Months Ended September 30, | Three Months Ended September 30, | Less FX                                 | Constant Currency                       | Less                                    | Hedging                                 |                                         | Constant Currency Revenues              |\\n|                                    | 2023                             | 2024                             | Effect                                  | Revenues                                | Reported Effect                         |                                         | Less FX Effect                          |                                         |\\n| United States                      | $ 36,354                         | $ 43,139                         | $ 0                                     | $ 43,139                                | 19 %                                    |                                         | 0%                                      | 19 %                                    |\\n| EMEA                               | 22,661                           | 25,472                           | (146)                                   | 25,618                                  | 12 %                                    |                                         | (1)%                                    | 13 %                                    |\\n| APAC                               | 13,126                           | 14,547                           | (285)                                   | 14,832                                  | 11 %                                    |                                         | (2)%                                    | 13 %                                    |\\n| Other Americas                     | 4,553                            | 5,093                            | (586)                                   | 5,679                                   | 12 %                                    |                                         | (13)%                                   | 25 %                                    |\\n| Revenues, excluding hedging effect | 76,694                           | 88,251                           | (1,017)                                 | 89,268                                  | 15 %                                    |                                         | (1)%                                    | 16 %                                    |\\n| Hedging gains (losses)             | (1)                              | 17                               |                                         |                                         |                                         |                                         |                                         |                                         |\\n| Total revenues (1)                 | $ 76,693                         | $ 88,268                         | $                                       | 89,268                                  | 15 %                                    | 0 %                                     | (1)%                                    | 16 %                                    |\\n\\nTotal constant currency revenues of $89.3 billion for the three months ended September 30, 2024 increased $12.6 billion compared to $76.7 billion in revenues, excluding hedging effect, for the three months ended September 30, 2023. (1)\\n\\nEMEA  revenue  growth  was  unfavorably  affected  by  changes  in  foreign  currency  exchange  rates,  primarily  due  to  the  U.S.  dollar strengthening relative to the Turkish lira.\\n\\nAPAC  revenue  growth  was  unfavorably  affected  by  changes  in  foreign  currency  exchange  rates,  primarily  due  to  the  U.S.  dollar strengthening relative to the Japanese yen.\\n\\nOther Americas revenue growth was unfavorably affected by changes in foreign currency exchange rates, primarily due to the U.S. dollar strengthening relative to the Argentine peso and the Brazilian real.\\n\\n|                                    |                                 |                                 | Nine Months Ended September 30, 2024   | Nine Months Ended September 30, 2024   | Nine Months Ended September 30, 2024   | Nine Months Ended September 30, 2024   | Nine Months Ended September 30, 2024   | Nine Months Ended September 30, 2024   |\\n|------------------------------------|---------------------------------|---------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|\\n|                                    |                                 |                                 |                                        |                                        | %Change from Prior Period              | %Change from Prior Period              | %Change from Prior Period              | %Change from Prior Period              |\\n|                                    | Nine Months Ended September 30, | Nine Months Ended September 30, | Less FX                                | Constant                               |                                        |                                        |                                        | Constant                               |\\n|                                    | 2023                            | 2024                            |                                        | Currency                               |                                        | Less Hedging                           |                                        | Currency                               |\\n|                                    |                                 |                                 | Effect                                 | Revenues                               | As Reported                            | Effect                                 | Less FX Effect                         | Revenues                               |\\n| United States                      | $ 104,291                       | $ 123,072                       | $ 0                                    | $ 123,072                              | 18 %                                   |                                        | 0%                                     | 18 %                                   |\\n| EMEA                               | 66,028                          | 73,943                          | (309)                                  | 74,252                                 | 12 %                                   |                                        | 0%                                     | 12 %                                   |\\n| APAC                               | 37,535                          | 41,659                          | (1,319)                                | 42,978                                 | 11 %                                   |                                        | (4)%                                   | 15 %                                   |\\n| Other Americas                     | 13,144                          | 14,684                          | (1,043)                                | 15,727                                 | 12 %                                   |                                        | (8)%                                   | 20 %                                   |\\n| Revenues, excluding hedging effect | 220,998                         | 253,358                         | (2,671)                                | 256,029                                | 15 %                                   |                                        | (1)%                                   | 16 %                                   |\\n| Hedging gains (losses)             | 86                              | 191                             |                                        |                                        |                                        |                                        |                                        |                                        |\\n| Total revenues (1)                 | $ 221,084                       | $ 253,549                       | $                                      | 256,029                                | 15 %                                   | 0 %                                    | (1)%                                   | 16 %                                   |\\n\\nTotal constant currency revenues of $256.0 billion for the nine months ended September 30, 2024 increased $35.0 billion compared to $221.1 billion in revenues, excluding hedging effect, for the nine months ended September 30, 2023. (1)\\n\\nEMEA  revenue  growth  was  not  materially  affected  by  changes  in  foreign  currency  exchange  rates,  as  the  effect  of  the  U.S.  dollar strengthening relative to the Turkish lira was largely offset by the U.S. dollar weakening relative to the British pound.\\n\\nAPAC  revenue  growth  was  unfavorably  affected  by  changes  in  foreign  currency  exchange  rates,  primarily  due  to  the  U.S.  dollar strengthening relative to the Japanese yen.\\n\\nOther Americas revenue growth was unfavorably affected by changes in foreign currency exchange rates, primarily due to the U.S. dollar strengthening relative to the Argentine peso.\\n\\n## Costs and Expenses\\n\\n'),\n",
       " Document(metadata={'fiscal_quarter': 'q1', 'fiscal_year': 2025, 'company_name': 'amazon', 'doc_type': '10-q', 'page': 9, 'file_hash': 'a06e0bf6d1ba3aac6b82958c381af08b4d476677484170264f6ae8d64fc4fe67', 'source_file': 'amazon 10-q q1 2025.pdf', '_id': 'e116c420-7b27-4ba9-a4ea-03f3f93282bd', '_collection_name': 'financial_docs'}, page_content=\"\\n\\nvendors, or liquidations, and expected recoverable values of each disposition category. The inventory valuation allowance, representing a write-down of inventory, was $3.0 billion and $2.8 billion as of December 31, 2024 and March 31, 2025.\\n\\n## Accounts Receivable, Net and Other\\n\\nIncluded in 'Accounts receivable, net and other' on our consolidated balance sheets are receivables primarily related to customers, vendors, and prepaid expenses and other current assets. As of December 31, 2024 and March 31, 2025, customer receivables, net, were $34.3 billion and $35.5 billion, vendor receivables, net, were $11.6 billion and $9.1 billion, and other receivables, net, were $3.4 billion. Prepaid expenses and other current assets, which include amounts related to non-income taxes and satellite network launch services deposits, were $6.3 billion and $6.2 billion as of December 31, 2024 and March 31, 2025. We currently expense satellite network launch services deposits upon launch to 'Technology and infrastructure.'\\n\\nWe estimate losses on receivables based on expected losses, including our historical experience of actual losses. The allowance for doubtful accounts was $2.0 billion as of December 31, 2024 and March 31, 2025.\\n\\n## Digital Video and Music Content\\n\\nIncluded in 'Other assets' on our consolidated balance sheets are the total capitalized costs of video, which is primarily released content, and music, which as of December 31, 2024 and March 31, 2025 were $19.6 billion and $20.3 billion. Total video and music expense was $4.6 billion and $5.1 billion in Q1 2024 and Q1 2025.\\n\\n## Unearned Revenue\\n\\nUnearned revenue is recorded when payments are received or due in advance of performing our service obligations and is recognized over the service period. Unearned revenue primarily relates to prepayments of AWS services and Amazon Prime memberships. Our total unearned revenue as of December 31, 2024 was $24.6 billion, of which $7.0 billion was recognized as revenue during the three months ended March 31, 2025. Included in 'Other long-term liabilities' on our consolidated balance sheets was $6.5 billion and $4.9 billion of unearned revenue as of December 31, 2024 and March 31, 2025.\\n\\nAdditionally, we have performance obligations, primarily related to AWS, associated with commitments in customer contracts for future services that have not yet been recognized in our consolidated financial statements. For contracts with original terms that exceed one year, those commitments not yet recognized were approximately $189 billion as of March 31, 2025. The weighted-average remaining life of our long-term contracts is 4.1 years. However, the amount and timing of revenue recognition is largely driven by customer usage, which can extend beyond the original contractual term.\\n\\n## Accounting Pronouncements Not Yet Adopted\\n\\nIn December 2023, the Financial Accounting Standards Board ('FASB') issued an Accounting Standards Update ('ASU') amending existing income tax disclosure guidance, primarily requiring more detailed disclosure for income taxes paid and the effective tax rate reconciliation. The ASU is effective for annual reporting periods beginning after December 15, 2024, with early adoption permitted and can be applied on either a prospective or retroactive basis. We expect to adopt the ASU on a retroactive basis.\\n\\nIn November 2024, the FASB issued an ASU amending existing income statement disclosure guidance, primarily requiring more detailed disclosure for expenses. The ASU is effective for annual reporting periods beginning after December 15, 2026, and interim periods within fiscal years beginning after December 15, 2027, with early adoption permitted. The amendments can be applied on either a prospective or retroactive basis. We are currently evaluating the ASU to determine its impact on our disclosures.\\n\\n\"),\n",
       " Document(metadata={'fiscal_quarter': 'q2', 'fiscal_year': 2024, 'company_name': 'google', 'doc_type': '10-q', 'page': 39, 'file_hash': 'c2e9e49341c71edbe785ae4908a0b3ca21dbb57c76fba471f171803fd5889dc3', 'source_file': 'google 10-q q2 2024.pdf', '_id': 'f9f60c75-189b-42f0-b400-d319df25e132', '_collection_name': 'financial_docs'}, page_content='\\n\\nFor additional information, see Note 2 of the Notes to Consolidated Financial Statements included in Item 1 of this Quarterly Report on Form 10-Q.\\n\\n## Use of Non-GAAP Constant Currency Information\\n\\nInternational revenues, which represent a significant portion of our revenues, are generally transacted in multiple currencies and therefore are affected by fluctuations in foreign currency exchange rates.\\n\\nThe effect of currency exchange rates on our business is an important factor in understanding period-to-period comparisons. We use nonGAAP  constant  currency  revenues  (\"constant  currency  revenues\")  and  non-GAAP  percentage  change  in  constant  currency  revenues (\"percentage change in constant currency revenues\") for financial and operational decision-making and as a means to evaluate period-to-period comparisons.  We  believe  the  presentation  of  results  on  a  constant  currency  basis  in  addition  to  GAAP  results  helps  improve  the  ability  to understand our performance, because it excludes the effects of foreign currency volatility that are not indicative of our core operating results.\\n\\nConstant  currency  information  compares  results  between  periods  as  if  exchange  rates  had  remained  constant  period  over  period.  We define  constant  currency  revenues  as  revenues  excluding  the  effect  of  foreign  currency  exchange  rate  movements  (\"FX  Effect\")  as  well  as hedging  activities,  which  are  recognized  at  the  consolidated  level.  We  use  constant  currency  revenues  to  determine  the  constant  currency revenue percentage change on a year-on-year basis. Constant currency revenues are calculated by translating current period revenues using prior year comparable period exchange rates, as well as excluding any hedging effects realized in the current period.\\n\\nConstant  currency  revenue  percentage  change  is  calculated  by  determining  the  change  in  current  period  revenues  over  prior  year comparable period revenues where current period foreign currency revenues are translated using prior year comparable period exchange rates and hedging effects are excluded from revenues of both periods.\\n\\nThese results should be considered in addition to, not as a substitute for, results reported in accordance with GAAP. Results on a constant currency basis, as we present them, may not be comparable to similarly titled measures used by other companies and are not a measure of performance presented in accordance with GAAP.\\n\\nThe  following  table  presents  the  foreign  currency  exchange  effect  on  international  revenues  and  total  revenues  (in  millions,  except percentages):\\n\\n|                                    |                             |                             | Three Months Ended June 30, 2024   | Three Months Ended June 30, 2024   | Three Months Ended June 30, 2024   | Three Months Ended June 30, 2024   | Three Months Ended June 30, 2024   | Three Months Ended June 30, 2024   |\\n|------------------------------------|-----------------------------|-----------------------------|------------------------------------|------------------------------------|------------------------------------|------------------------------------|------------------------------------|------------------------------------|\\n|                                    |                             |                             |                                    |                                    | %Change from Prior Period          | %Change from Prior Period          | %Change from Prior Period          | %Change from Prior Period          |\\n|                                    | Three Months Ended June 30, | Three Months Ended June 30, | Less FX                            | Constant Currency                  |                                    | Less Hedging                       |                                    | Constant                           |\\n|                                    | 2023                        | 2024                        | Effect                             |                                    |                                    |                                    | Less FX Effect                     | Currency                           |\\n|                                    |                             |                             |                                    | Revenues                           | As Reported                        | Effect                             |                                    | Revenues                           |\\n| United States                      | $ 35,073                    | $ 41,196                    | $ 0                                | $ 41,196                           | 17 %                               |                                    | 0%                                 | 17 %                               |\\n| EMEA                               | 22,289                      | 24,683                      | (367)                              | 25,050                             | 11 %                               |                                    | (1)%                               | 12 %                               |\\n| APAC                               | 12,728                      | 13,823                      | (595)                              | 14,418                             | 9 %                                |                                    | (4)%                               | 13 %                               |\\n| Other Americas                     | 4,511                       | 4,938                       | (305)                              | 5,243                              | 9 %                                |                                    | (7)%                               | 16 %                               |\\n| Revenues, excluding hedging effect | 74,601                      | 84,640                      | (1,267)                            | 85,907                             | 13 %                               |                                    | (2)%                               | 15 %                               |\\n| Hedging gains (losses)             | 3                           | 102                         |                                    |                                    |                                    |                                    |                                    |                                    |\\n| Total revenues (1)                 | $ 74,604                    | $ 84,742                    | $                                  | 85,907                             | 14 %                               | 1 %                                | (2)%                               | 15 %                               |\\n\\nTotal constant currency revenues of $85.9 billion for the three months ended June 30, 2024 increased $11.3 billion compared to $74.6 billion in revenues, excluding hedging effect, for the three months ended June 30, 2023. (1)\\n\\nEMEA  revenue  growth  was  unfavorably  affected  by  changes  in  foreign  currency  exchange  rates,  primarily  due  to  the  U.S.  dollar strengthening relative to the Turkish lira.\\n\\nAPAC  revenue  growth  was  unfavorably  affected  by  changes  in  foreign  currency  exchange  rates,  primarily  due  to  the  U.S.  dollar strengthening relative to the Japanese yen.\\n\\nOther Americas revenue growth was unfavorably affected by changes in foreign currency exchange rates, primarily due to the U.S. dollar strengthening relative to the Argentine peso.\\n\\n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
