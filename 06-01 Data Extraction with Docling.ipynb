{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Extraction with Docling\n",
        "\n",
        "In this notebook, we'll extract content from PDFs into structured formats:\n",
        "\n",
        "- **Markdown**: Full document text with page breaks for chunking\n",
        "- **Images**: Save pages containing large charts/diagrams (>500x500 pixels)\n",
        "- **Tables**: Extract with 2 paragraphs of context + page number metadata\n",
        "\n",
        "**Pipeline Overview:**\n",
        "1. **This Notebook (06-01)**: Extract PDFs → Markdown, Images, Tables\n",
        "2. **Next Notebook (06-02)**: Load into vector database with embeddings\n",
        "3. **Notebook 07**: Intelligent search with filters and reranking\n",
        "\n",
        "**Output Structure:**\n",
        "```\n",
        "data/markdown/{company}/{document}.md\n",
        "data/images/{company}/{document}/page_5.png\n",
        "data/tables/{company}/{document}/table_1_page_5.md\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "from docling_core.types.doc import PictureItem\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Directory paths\n",
        "DATA_DIR = \"data/rag-data/pdfs\"\n",
        "OUTPUT_MD_DIR = \"data/rag-data/markdown\"\n",
        "OUTPUT_IMAGES_DIR = \"data/rag-data/images\"\n",
        "OUTPUT_TABLES_DIR = \"data/rag-data/tables\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_metadata_from_filename(filename: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract metadata from filename.\n",
        "    \n",
        "    Expected format: CompanyName DocType [Quarter] Year.pdf\n",
        "    Examples:\n",
        "        - Amazon 10-Q Q1 2024.pdf\n",
        "        - Microsoft 10-K 2023.pdf\n",
        "    \"\"\"\n",
        "    parts = filename.split()\n",
        "    \n",
        "    return {\n",
        "        'company_name': parts[0],\n",
        "        'doc_type': parts[1],\n",
        "        'fiscal_quarter': parts[2] if len(parts) == 4 else None,\n",
        "        'fiscal_year': int(parts[-1])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_context_and_table(lines: List[str], table_index: int) -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    Extract context and table content at a specific position.\n",
        "    \n",
        "    Args:\n",
        "        lines: All markdown lines\n",
        "        table_index: Where the table starts\n",
        "    \n",
        "    Returns:\n",
        "        (combined_content, next_line_index)\n",
        "    \"\"\"\n",
        "    # Get 2 paragraphs before the table\n",
        "    context_lines = []\n",
        "    para_count = 0\n",
        "    j = table_index - 1\n",
        "    \n",
        "    while j >= 0 and para_count < 2:\n",
        "        if lines[j].strip():\n",
        "            if '<!-- page break -->' not in lines[j]:\n",
        "                context_lines.insert(0, lines[j])\n",
        "        elif context_lines:\n",
        "            para_count += 1\n",
        "        j -= 1\n",
        "    \n",
        "    # Get all table rows\n",
        "    table_lines = []\n",
        "    i = table_index\n",
        "    \n",
        "    while i < len(lines):\n",
        "        if lines[i].strip().startswith('|'):\n",
        "            table_lines.append(lines[i])\n",
        "            i += 1\n",
        "        elif not lines[i].strip():\n",
        "            i += 1  # Skip empty lines within table\n",
        "        else:\n",
        "            break  # End of table\n",
        "    \n",
        "    # Combine them\n",
        "    content = '\\n'.join(context_lines) + '\\n\\n' + '\\n'.join(table_lines)\n",
        "    return content, i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tables_with_context(markdown_text: str) -> List[Tuple[str, str, int]]:\n",
        "    \"\"\"\n",
        "    Find all tables and extract them with context and page numbers.\n",
        "    \n",
        "    Returns:\n",
        "        List of (content, table_name, page_number)\n",
        "    \"\"\"\n",
        "    lines = markdown_text.split('\\n')\n",
        "    tables = []\n",
        "    current_page = 1\n",
        "    table_num = 1\n",
        "    i = 0\n",
        "    \n",
        "    while i < len(lines):\n",
        "        # Track page numbers\n",
        "        if '<!-- page break -->' in lines[i]:\n",
        "            current_page += 1\n",
        "            i += 1\n",
        "            continue\n",
        "        \n",
        "        # Found a table?\n",
        "        if lines[i].strip().startswith('|') and lines[i].count('|') >= 2:\n",
        "            content, next_i = extract_context_and_table(lines, i)\n",
        "            tables.append((content, f\"table_{table_num}\", current_page))\n",
        "            table_num += 1\n",
        "            i = next_i\n",
        "        else:\n",
        "            i += 1\n",
        "    \n",
        "    return tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_pdf_to_docling(pdf_path: Path):\n",
        "    \"\"\"\n",
        "    Convert PDF using Docling.\n",
        "    \n",
        "    Returns:\n",
        "        Docling conversion result\n",
        "    \"\"\"\n",
        "    pipeline_options = PdfPipelineOptions()\n",
        "    pipeline_options.generate_picture_images = True\n",
        "    pipeline_options.generate_page_images = True\n",
        "    \n",
        "    converter = DocumentConverter(\n",
        "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
        "    )\n",
        "    \n",
        "    return converter.convert(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_page_images(result, images_dir: Path):\n",
        "    \"\"\"\n",
        "    Find and save pages with large images (>500x500 pixels).\n",
        "    \"\"\"\n",
        "    pages_to_save = set()\n",
        "    \n",
        "    for item in result.document.iterate_items():\n",
        "        element = item[0]\n",
        "        \n",
        "        if isinstance(element, PictureItem):\n",
        "            image = element.get_image(result.document)\n",
        "            if image.size[0] > 500 and image.size[1] > 500:\n",
        "                page_no = element.prov[0].page_no if element.prov else None\n",
        "                if page_no:\n",
        "                    pages_to_save.add(page_no)\n",
        "    \n",
        "    # Save images\n",
        "    for page_no in pages_to_save:\n",
        "        page = result.document.pages[page_no]\n",
        "        page.image.pil_image.save(images_dir / f\"page_{page_no}.png\", \"PNG\")\n",
        "    \n",
        "    if pages_to_save:\n",
        "        print(f\"  ✓ Saved {len(pages_to_save)} page images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_tables(markdown_text: str, tables_dir: Path):\n",
        "    \"\"\"\n",
        "    Extract and save tables with context and page numbers.\n",
        "    \"\"\"\n",
        "    tables = extract_tables_with_context(markdown_text)\n",
        "    \n",
        "    for table_content, table_name, page_num in tables:\n",
        "        content_with_page = f\"**Page:** {page_num}\\n\\n{table_content}\"\n",
        "        (tables_dir / f\"{table_name}_page_{page_num}.md\").write_text(content_with_page, encoding='utf-8')\n",
        "    \n",
        "    if tables:\n",
        "        print(f\"  ✓ Saved {len(tables)} tables\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Main Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_pdf_content(pdf_path: Path):\n",
        "    \"\"\"Extract PDF to markdown, images, and tables.\"\"\"\n",
        "    print(f\"Processing: {pdf_path.name}\")\n",
        "    \n",
        "    # Setup output directories\n",
        "    filename = pdf_path.name.replace('.pdf', '')\n",
        "    metadata = extract_metadata_from_filename(filename)\n",
        "    company = metadata['company_name']\n",
        "    filename_stem = pdf_path.stem\n",
        "    \n",
        "    md_dir = Path(OUTPUT_MD_DIR) / company\n",
        "    images_dir = Path(OUTPUT_IMAGES_DIR) / company / filename_stem\n",
        "    tables_dir = Path(OUTPUT_TABLES_DIR) / company / filename_stem\n",
        "    \n",
        "    for dir_path in [md_dir, images_dir, tables_dir]:\n",
        "        dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Convert PDF with Docling\n",
        "    result = convert_pdf_to_docling(pdf_path)\n",
        "    \n",
        "    # Save markdown\n",
        "    markdown_text = result.document.export_to_markdown(page_break_placeholder=\"<!-- page break -->\")\n",
        "    (md_dir / f\"{filename_stem}.md\").write_text(markdown_text, encoding='utf-8')\n",
        "    print(f\"  ✓ Markdown saved\")\n",
        "    \n",
        "    # Save page images\n",
        "    save_page_images(result, images_dir)\n",
        "    \n",
        "    # Save tables\n",
        "    save_tables(markdown_text, tables_dir)\n",
        "    \n",
        "    print(f\"  Done!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Process a Single PDF (Example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all PDF files\n",
        "data_path = Path(DATA_DIR)\n",
        "pdf_files = list(data_path.rglob(\"*.pdf\"))\n",
        "print(f\"Found {len(pdf_files)} PDF files\\n\")\n",
        "\n",
        "# Process one example first to see the output\n",
        "if pdf_files:\n",
        "    print(\"=== Processing Example PDF ===\")\n",
        "    extract_pdf_content(pdf_files[0])\n",
        "    print(\"\\nCheck the output folders to see extracted files!\")\n",
        "    print(f\"- Markdown: {OUTPUT_MD_DIR}\")\n",
        "    print(f\"- Images: {OUTPUT_IMAGES_DIR}\")\n",
        "    print(f\"- Tables: {OUTPUT_TABLES_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Process All PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all PDFs\n",
        "print(f\"\\n=== Processing All {len(pdf_files)} PDFs ===\\n\")\n",
        "\n",
        "for idx, pdf_path in enumerate(pdf_files, 1):\n",
        "    print(f\"[{idx}/{len(pdf_files)}]\", end=\" \")\n",
        "    extract_pdf_content(pdf_path)\n",
        "\n",
        "print(\"\\n=== Extraction Complete ===\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
