{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Extraction with Docling\n",
        "\n",
        "In this notebook, we'll extract content from PDFs into structured formats:\n",
        "\n",
        "- **Markdown**: Full document text with page breaks for chunking\n",
        "- **Images**: Save pages containing large charts/diagrams (>500x500 pixels)\n",
        "- **Tables**: Extract with 2 paragraphs of context + page number metadata\n",
        "\n",
        "**Pipeline Overview:**\n",
        "1. **This Notebook (06-01)**: Extract PDFs → Markdown, Images, Tables\n",
        "2. **Next Notebook (06-02)**: Load into vector database with embeddings\n",
        "3. **Notebook 07**: Intelligent search with filters and reranking\n",
        "\n",
        "**Output Structure:**\n",
        "```\n",
        "data/rag-markdown/{company}/{document}.md\n",
        "data/rag-images/{company}/{document}/page_5.png\n",
        "data/rag-tables/{company}/{document}/table_1_page_5.md\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "from docling_core.types.doc import PictureItem\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Directory paths\n",
        "DATA_DIR = \"data/rag-data/rag-pdf\"\n",
        "OUTPUT_MD_DIR = \"data/rag-data/rag-markdown\"\n",
        "OUTPUT_IMAGES_DIR = \"data/rag-data/rag-images\"\n",
        "OUTPUT_TABLES_DIR = \"data/rag-data/rag-tables\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_metadata_from_filename(filename: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract metadata from filename.\n",
        "    \n",
        "    Expected format: CompanyName DocType [Quarter] Year.pdf\n",
        "    Examples:\n",
        "        - Amazon 10-Q Q1 2024.pdf\n",
        "        - Microsoft 10-K 2023.pdf\n",
        "    \"\"\"\n",
        "    name = filename.replace('.pdf', '')\n",
        "    parts = name.split()\n",
        "    \n",
        "    return {\n",
        "        'company_name': parts[0],\n",
        "        'doc_type': parts[1],\n",
        "        'fiscal_quarter': parts[2] if len(parts) == 4 else None,\n",
        "        'fiscal_year': int(parts[-1])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tables_with_context(markdown_text: str) -> List[Tuple[str, str, int]]:\n",
        "    \"\"\"\n",
        "    Extract markdown tables with 2 paragraphs of context and page number.\n",
        "    \n",
        "    Returns:\n",
        "        List of (context + table, table_name, page_number) tuples\n",
        "    \"\"\"\n",
        "    lines = markdown_text.split('\\n')\n",
        "    tables = []\n",
        "    i = 0\n",
        "    table_num = 1\n",
        "    current_page = 1  # Track current page number\n",
        "    \n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        \n",
        "        # Update page number when we hit a page break\n",
        "        if '<!-- page break -->' in line:\n",
        "            current_page += 1\n",
        "            i += 1\n",
        "            continue\n",
        "        \n",
        "        # Check if this line is a table row (markdown tables start with |)\n",
        "        if line.strip().startswith('|') and line.count('|') >= 2:\n",
        "            \n",
        "            # Step 1: Extract 2 paragraphs before the table\n",
        "            context_lines = []\n",
        "            para_count = 0\n",
        "            j = i - 1\n",
        "            \n",
        "            while j >= 0 and para_count < 2:\n",
        "                if lines[j].strip():  # Non-empty line\n",
        "                    # Skip page break markers in context\n",
        "                    if '<!-- page break -->' not in lines[j]:\n",
        "                        context_lines.insert(0, lines[j])\n",
        "                elif context_lines:  # Empty line = paragraph break\n",
        "                    para_count += 1\n",
        "                j -= 1\n",
        "            \n",
        "            # Step 2: Extract the full table\n",
        "            table_lines = []\n",
        "            while i < len(lines) and (lines[i].strip().startswith('|') or not lines[i].strip()):\n",
        "                if lines[i].strip():\n",
        "                    table_lines.append(lines[i])\n",
        "                i += 1\n",
        "                # Stop when we hit a non-table line\n",
        "                if i < len(lines) and lines[i].strip() and not lines[i].strip().startswith('|'):\n",
        "                    break\n",
        "            \n",
        "            # Step 3: Combine context + table\n",
        "            full_content = '\\n'.join(context_lines) + '\\n\\n' + '\\n'.join(table_lines)\n",
        "            tables.append((full_content, f\"table_{table_num}\", current_page))\n",
        "            table_num += 1\n",
        "        else:\n",
        "            i += 1\n",
        "    \n",
        "    return tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Main Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_pdf_content(pdf_path: Path):\n",
        "    \"\"\"Extract PDF to markdown, images, and tables.\"\"\"\n",
        "    print(f\"Processing: {pdf_path.name}\")\n",
        "    \n",
        "    # Step 1: Get metadata and create output directories\n",
        "    metadata = extract_metadata_from_filename(pdf_path.name)\n",
        "    company = metadata['company_name']\n",
        "    filename_stem = pdf_path.stem\n",
        "    \n",
        "    md_dir = Path(OUTPUT_MD_DIR) / company\n",
        "    images_dir = Path(OUTPUT_IMAGES_DIR) / company / filename_stem\n",
        "    tables_dir = Path(OUTPUT_TABLES_DIR) / company / filename_stem\n",
        "    \n",
        "    for dir_path in [md_dir, images_dir, tables_dir]:\n",
        "        dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Step 2: Configure Docling converter\n",
        "    pipeline_options = PdfPipelineOptions()\n",
        "    pipeline_options.generate_picture_images = True\n",
        "    pipeline_options.generate_page_images = True\n",
        "    \n",
        "    converter = DocumentConverter(\n",
        "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
        "    )\n",
        "    result = converter.convert(str(pdf_path))\n",
        "    \n",
        "    # Step 3: Save markdown with page breaks\n",
        "    markdown_text = result.document.export_to_markdown(page_break_placeholder=\"<!-- page break -->\")\n",
        "    (md_dir / f\"{filename_stem}.md\").write_text(markdown_text, encoding='utf-8')\n",
        "    print(f\"  ✓ Markdown saved\")\n",
        "    \n",
        "    # Step 4: Find and save pages with large images\n",
        "    pages_to_save = set()\n",
        "    \n",
        "    for item in result.document.iterate_items():\n",
        "        element = item[0]  # Extract element from tuple\n",
        "        \n",
        "        if isinstance(element, PictureItem):\n",
        "            image = element.get_image(result.document)\n",
        "            # Check if image is large (>500x500 pixels)\n",
        "            if image.size[0] > 500 and image.size[1] > 500:\n",
        "                page_no = element.prov[0].page_no if element.prov else None\n",
        "                if page_no:\n",
        "                    pages_to_save.add(page_no)\n",
        "    \n",
        "    # Save the full page images\n",
        "    for page_no in pages_to_save:\n",
        "        page = result.document.pages[page_no]\n",
        "        page.image.pil_image.save(images_dir / f\"page_{page_no}.png\", \"PNG\")\n",
        "    \n",
        "    if pages_to_save:\n",
        "        print(f\"  ✓ Saved {len(pages_to_save)} page images\")\n",
        "    \n",
        "    # Step 5: Extract and save tables with context and page numbers\n",
        "    tables = extract_tables_with_context(markdown_text)\n",
        "    for table_content, table_name, page_num in tables:\n",
        "        # Add page number metadata at the top\n",
        "        content_with_page = f\"**Page:** {page_num}\\n\\n{table_content}\"\n",
        "        # Save with page number in filename\n",
        "        (tables_dir / f\"{table_name}_page_{page_num}.md\").write_text(content_with_page, encoding='utf-8')\n",
        "    \n",
        "    if tables:\n",
        "        print(f\"  ✓ Saved {len(tables)} tables\")\n",
        "    \n",
        "    print(f\"  Done!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Process a Single PDF (Example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all PDF files\n",
        "data_path = Path(DATA_DIR)\n",
        "pdf_files = list(data_path.rglob(\"*.pdf\"))\n",
        "print(f\"Found {len(pdf_files)} PDF files\\n\")\n",
        "\n",
        "# Process one example first to see the output\n",
        "if pdf_files:\n",
        "    print(\"=== Processing Example PDF ===\")\n",
        "    extract_pdf_content(pdf_files[0])\n",
        "    print(\"\\nCheck the output folders to see extracted files!\")\n",
        "    print(f\"- Markdown: {OUTPUT_MD_DIR}\")\n",
        "    print(f\"- Images: {OUTPUT_IMAGES_DIR}\")\n",
        "    print(f\"- Tables: {OUTPUT_TABLES_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Process All PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all PDFs\n",
        "print(f\"\\n=== Processing All {len(pdf_files)} PDFs ===\\n\")\n",
        "\n",
        "for idx, pdf_path in enumerate(pdf_files, 1):\n",
        "    print(f\"[{idx}/{len(pdf_files)}]\", end=\" \")\n",
        "    extract_pdf_content(pdf_path)\n",
        "\n",
        "print(\"\\n=== Extraction Complete ===\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
