{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c246f8",
   "metadata": {},
   "source": [
    "## Advanced RAG - Retrieval Strategies\n",
    "### Dense, Sparse, Hybrid, and Reranking\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand different retrieval modes\n",
    "- Implement hybrid search with filters\n",
    "- Apply reranking for better results\n",
    "- Build reusable retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\n",
    "from langchain_huggingface import HuggingFaceCrossEncoder\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spk2r8g5bmn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "COLLECTION_NAME = \"financial_docs\"\n",
    "EMBEDDING_MODEL = \"models/gemini-embedding-001\"\n",
    "RERANKER_MODEL = \"BAAI/bge-reranker-base\"\n",
    "LLM_MODEL = \"gemini-2.0-flash-exp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ozx3ijhb",
   "metadata": {},
   "source": [
    "### Metadata Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dic5wiy82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocType(str, Enum):\n",
    "    TEN_K = \"10-k\"\n",
    "    TEN_Q = \"10-q\"\n",
    "    EIGHT_K = \"8-k\"\n",
    "\n",
    "class FiscalQuarter(str, Enum):\n",
    "    Q1 = \"q1\"\n",
    "    Q2 = \"q2\"\n",
    "    Q3 = \"q3\"\n",
    "    Q4 = \"q4\"\n",
    "\n",
    "class ChunkMetadata(BaseModel):\n",
    "    company_name: Optional[str] = Field(default=None, description=\"Company name (lowercase, eg. 'amazon', 'apple', 'google',...)\")\n",
    "    doc_type: Optional[DocType] = Field(default=None, description=\"Document type (10-k, 10-q, 8-k, etc.)\")\n",
    "    fiscal_year: Optional[int] = Field(default=None, ge=1950, le=2050, description=\"Fiscal year of the document\")\n",
    "    fiscal_quarter: Optional[FiscalQuarter] = Field(default=None, description=\"Fiscal quarter (q1-q4) if applicable\")\n",
    "    \n",
    "    model_config = {\"use_enum_values\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70zbbwuz6vi",
   "metadata": {},
   "source": [
    "### Initialize LLM and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wjoy0ntvpqp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatGoogleGenerativeAI(model=LLM_MODEL)\n",
    "\n",
    "# Dense embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "# Sparse embeddings\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# Connect to existing collection\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    url=\"http://localhost:6333\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ry4fp8i22q",
   "metadata": {},
   "source": [
    "### Filter Extraction with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p0qlcnkjg1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filters(user_query: str):\n",
    "    \"\"\"\n",
    "    Extract metadata filters from natural language query using LLM.\n",
    "    \n",
    "    Args:\n",
    "        user_query: Natural language query from user\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted filters (only non-None values)\n",
    "    \"\"\"\n",
    "    llm_structured = llm.with_structured_output(ChunkMetadata)\n",
    "    \n",
    "    prompt = f\"\"\"Extract metadata filters from the query. Return None for fields not mentioned.\n",
    "\n",
    "                USER QUERY: {user_query}\n",
    "\n",
    "                COMPANY MAPPINGS:\n",
    "                - Amazon/AMZN -> amazon\n",
    "                - Google/Alphabet/GOOGL/GOOG -> google\n",
    "                - Apple/AAPL -> apple\n",
    "                - Microsoft/MSFT -> microsoft\n",
    "                - Tesla/TSLA -> tesla\n",
    "                - Nvidia/NVDA -> nvidia\n",
    "                - Meta/Facebook/FB -> meta\n",
    "\n",
    "                DOC TYPE:\n",
    "                - Annual report -> 10-k\n",
    "                - Quarterly report -> 10-q\n",
    "                - Current report -> 8-k\n",
    "\n",
    "                EXAMPLES:\n",
    "                \"Amazon Q3 2024 revenue\" -> {{\"company_name\": \"amazon\", \"doc_type\": \"10-q\", \"fiscal_year\": 2024, \"fiscal_quarter\": \"q3\"}}\n",
    "                \"Apple 2023 annual report\" -> {{\"company_name\": \"apple\", \"doc_type\": \"10-k\", \"fiscal_year\": 2023}}\n",
    "                \"Tesla profitability\" -> {{\"company_name\": \"tesla\"}}\n",
    "\n",
    "                Extract metadata:\n",
    "                \"\"\"\n",
    "    \n",
    "    metadata = llm_structured.invoke(prompt)\n",
    "    filters = metadata.model_dump(exclude_none=True)\n",
    "    \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llfr2yc3x2c",
   "metadata": {},
   "source": [
    "### Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a2z68d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_results(query: str, documents: list, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Rerank documents using cross-encoder.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        documents: List of Document objects\n",
    "        top_k: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (score, Document) tuples sorted by relevance\n",
    "    \"\"\"\n",
    "    reranker = HuggingFaceCrossEncoder(model_name=RERANKER_MODEL)\n",
    "    query_doc_pairs = [(query, doc.page_content) for doc in documents]\n",
    "    scores = reranker.score(query_doc_pairs)\n",
    "    reranked = sorted(zip(scores, documents), key=lambda x: x[0], reverse=True)\n",
    "    return reranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zthrewknofa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_reranking(query: str, k: int = 10, top_k: int = 5, filters: dict = None):\n",
    "    \"\"\"\n",
    "    Complete retrieval pipeline: hybrid search + reranking.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of results to fetch before reranking\n",
    "        top_k: Number of results to return after reranking\n",
    "        filters: Optional filters\n",
    "    \n",
    "    Returns:\n",
    "        List of (score, Document) tuples\n",
    "    \"\"\"\n",
    "    # Step 1: Hybrid search\n",
    "    initial_results = hybrid_search(query, k=k, filters=filters)\n",
    "    \n",
    "    # Step 2: Rerank\n",
    "    reranked = rerank_results(query, initial_results, top_k=top_k)\n",
    "    \n",
    "    return reranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t62il1teeu",
   "metadata": {},
   "source": [
    "### Test Filter Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1tovnoi6ryp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test filter extraction\n",
    "test_queries = [\n",
    "    \"Amazon Q3 2024 revenue\",\n",
    "    \"Apple 2023 annual report\",\n",
    "    \"Tesla profitability\",\n",
    "    \"What was Google's performance in Q2 2024?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    filters = extract_filters(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Filters: {filters}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2djsayppoi1",
   "metadata": {},
   "source": [
    "### Example 1: Basic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vp3uw5p9ng",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hybrid_search(\"What is the revenue?\", k=5)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. Company: {doc.metadata['company_name']} | Year: {doc.metadata['fiscal_year']} | Page: {doc.metadata['page']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzjl4px897a",
   "metadata": {},
   "source": [
    "### Example 2: Dynamic Filter Extraction + Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roh981ufupp",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What was Amazon's revenue in Q1 2024?\"\n",
    "\n",
    "# Extract filters dynamically\n",
    "filters = extract_filters(user_query)\n",
    "print(f\"Extracted filters: {filters}\\n\")\n",
    "\n",
    "# Search with extracted filters\n",
    "results = hybrid_search(user_query, k=5, filters=filters)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. Company: {doc.metadata['company_name']} | Year: {doc.metadata['fiscal_year']} | Quarter: {doc.metadata.get('fiscal_quarter')} | Page: {doc.metadata['page']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nqzwja4wc39",
   "metadata": {},
   "source": [
    "### Example 3: Dynamic Filters + Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yimwuwdryc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Show me Tesla's annual report for 2023\"\n",
    "\n",
    "# Extract filters\n",
    "filters = extract_filters(user_query)\n",
    "print(f\"Extracted filters: {filters}\\n\")\n",
    "\n",
    "# Retrieve with reranking\n",
    "reranked_results = retrieve_with_reranking(\n",
    "    query=user_query,\n",
    "    k=10,\n",
    "    top_k=5,\n",
    "    filters=filters\n",
    ")\n",
    "\n",
    "print(\"Reranked Results:\\n\")\n",
    "for i, (score, doc) in enumerate(reranked_results, 1):\n",
    "    print(f\"{i}. Score: {score:.4f} | Page: {doc.metadata['page']}\")\n",
    "    print(f\"   Content: {doc.page_content[:150]}...\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
