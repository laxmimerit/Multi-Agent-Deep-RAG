{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c246f8",
   "metadata": {},
   "source": [
    "## Advanced RAG - Retrieval Strategies\n",
    "### Dense, Sparse, Hybrid, and Reranking\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand different retrieval modes\n",
    "- Implement hybrid search with filters\n",
    "- Apply reranking for better results\n",
    "- Build reusable retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada0970",
   "metadata": {},
   "outputs": [],
   "source": "from dotenv import load_dotenv\nload_dotenv()\n\nfrom langchain_google_vertexai import VertexAIEmbeddings\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\nfrom langchain_community.cross_encoders import HuggingFaceCrossEncoder\nfrom qdrant_client.models import Filter, FieldCondition, MatchValue\n\nfrom scripts.schema import ChunkMetadata"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spk2r8g5bmn",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nCOLLECTION_NAME = \"financial_docs\"\nEMBEDDING_MODEL = \"multimodalembedding@001\"  # Vertex AI Multimodal\nRERANKER_MODEL = \"BAAI/bge-reranker-base\"\nLLM_MODEL = \"gemini-2.5-flash\""
  },
  {
   "cell_type": "markdown",
   "id": "70zbbwuz6vi",
   "metadata": {},
   "source": [
    "### Initialize LLM and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wjoy0ntvpqp",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize LLM\nllm = ChatGoogleGenerativeAI(model=LLM_MODEL)\n\n# Multimodal embeddings (Vertex AI) - works for text AND images\nembeddings = VertexAIEmbeddings(model_name=EMBEDDING_MODEL)\n\n# Sparse embeddings\nsparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n\n# Connect to existing collection\nvector_store = QdrantVectorStore.from_existing_collection(\n    embedding=embeddings,\n    sparse_embedding=sparse_embeddings,\n    collection_name=COLLECTION_NAME,\n    url=\"http://localhost:6333\",\n    retrieval_mode=RetrievalMode.HYBRID\n)"
  },
  {
   "cell_type": "markdown",
   "id": "ry4fp8i22q",
   "metadata": {},
   "source": [
    "### Filter Extraction with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "p0qlcnkjg1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filters(user_query: str):\n",
    "    \"\"\"\n",
    "    Extract metadata filters from natural language query using LLM.\n",
    "    \n",
    "    Args:\n",
    "        user_query: Natural language query from user\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted filters (only non-None values)\n",
    "    \"\"\"\n",
    "    llm_structured = llm.with_structured_output(ChunkMetadata)\n",
    "    \n",
    "    prompt = f\"\"\"Extract metadata filters from the query. Return None for fields not mentioned.\n",
    "\n",
    "                USER QUERY: {user_query}\n",
    "\n",
    "                COMPANY MAPPINGS:\n",
    "                - Amazon/AMZN -> amazon\n",
    "                - Google/Alphabet/GOOGL/GOOG -> google\n",
    "                - Apple/AAPL -> apple\n",
    "                - Microsoft/MSFT -> microsoft\n",
    "                - Tesla/TSLA -> tesla\n",
    "                - Nvidia/NVDA -> nvidia\n",
    "                - Meta/Facebook/FB -> meta\n",
    "\n",
    "                DOC TYPE:\n",
    "                - Annual report -> 10-k\n",
    "                - Quarterly report -> 10-q\n",
    "                - Current report -> 8-k\n",
    "\n",
    "                EXAMPLES:\n",
    "                \"Amazon Q3 2024 revenue\" -> {{\"company_name\": \"amazon\", \"doc_type\": \"10-q\", \"fiscal_year\": 2024, \"fiscal_quarter\": \"q3\"}}\n",
    "                \"Apple 2023 annual report\" -> {{\"company_name\": \"apple\", \"doc_type\": \"10-k\", \"fiscal_year\": 2023}}\n",
    "                \"Tesla profitability\" -> {{\"company_name\": \"tesla\"}}\n",
    "\n",
    "                Extract metadata:\n",
    "                \"\"\"\n",
    "    \n",
    "    metadata = llm_structured.invoke(prompt)\n",
    "    filters = metadata.model_dump(exclude_none=True)\n",
    "    \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llfr2yc3x2c",
   "metadata": {},
   "source": [
    "### Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbog1pt88k",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query: str, k: int = 5, filters: dict = None, content_types: list = None):\n",
    "    \"\"\"\n",
    "    Perform hybrid search (dense + sparse vectors).\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of results\n",
    "        filters: Optional filters like {\"company_name\": \"amazon\", \"fiscal_year\": 2024}\n",
    "        content_types: List of content types to search, e.g., [\"text\", \"table\"]\n",
    "    \n",
    "    Returns:\n",
    "        List of Document objects\n",
    "    \"\"\"\n",
    "    qdrant_filter = None\n",
    "    \n",
    "    if filters or content_types:\n",
    "        from qdrant_client.models import MatchAny\n",
    "        \n",
    "        conditions = []\n",
    "        \n",
    "        # Add must conditions from filters\n",
    "        if filters:\n",
    "            conditions.extend([\n",
    "                FieldCondition(key=f\"metadata.{key}\", match=MatchValue(value=value))\n",
    "                for key, value in filters.items()\n",
    "            ])\n",
    "        \n",
    "        # Add should condition for content_types\n",
    "        should_conditions = None\n",
    "        if content_types:\n",
    "            should_conditions = [\n",
    "                FieldCondition(key=\"metadata.content_type\", match=MatchValue(value=ct))\n",
    "                for ct in content_types\n",
    "            ]\n",
    "        \n",
    "        if conditions and should_conditions:\n",
    "            qdrant_filter = Filter(must=conditions, should=should_conditions, min_should_match=1)\n",
    "        elif conditions:\n",
    "            qdrant_filter = Filter(must=conditions)\n",
    "        elif should_conditions:\n",
    "            qdrant_filter = Filter(should=should_conditions, min_should_match=1)\n",
    "    \n",
    "    results = vector_store.similarity_search(query, k=k, filter=qdrant_filter)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065a2z68d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_results(query: str, documents: list, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Rerank documents using cross-encoder.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        documents: List of Document objects\n",
    "        top_k: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (score, Document) tuples sorted by relevance\n",
    "    \"\"\"\n",
    "    reranker = HuggingFaceCrossEncoder(model_name=RERANKER_MODEL)\n",
    "    query_doc_pairs = [(query, doc.page_content) for doc in documents]\n",
    "    scores = reranker.score(query_doc_pairs)\n",
    "    reranked = sorted(zip(scores, documents), key=lambda x: x[0], reverse=True)\n",
    "    return reranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zthrewknofa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_reranking(query: str, k: int = 10, top_k: int = 5, filters: dict = None, content_types: list = None):\n",
    "    \"\"\"\n",
    "    Complete retrieval pipeline: hybrid search + reranking.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of results to fetch before reranking\n",
    "        top_k: Number of results to return after reranking\n",
    "        filters: Optional filters\n",
    "        content_types: List of content types to search, e.g., [\"text\", \"table\"]\n",
    "    \n",
    "    Returns:\n",
    "        List of (score, Document) tuples\n",
    "    \"\"\"\n",
    "    # Step 1: Hybrid search\n",
    "    initial_results = hybrid_search(query, k=k, filters=filters, content_types=content_types)\n",
    "    \n",
    "    # Step 2: Rerank\n",
    "    reranked = rerank_results(query, initial_results, top_k=top_k)\n",
    "    \n",
    "    return reranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t62il1teeu",
   "metadata": {},
   "source": [
    "### Test Filter Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1tovnoi6ryp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Amazon Q3 2024 revenue\n",
      "Filters: {'company_name': 'amazon', 'doc_type': '10-q', 'fiscal_year': 2024, 'fiscal_quarter': 'q3'}\n",
      "\n",
      "Query: Apple 2023 annual report\n",
      "Filters: {'company_name': 'apple', 'doc_type': '10-k', 'fiscal_year': 2023}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test filter extraction\n",
    "test_queries = [\n",
    "    \"Amazon Q3 2024 revenue\",\n",
    "    \"Apple 2023 annual report\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    filters = extract_filters(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Filters: {filters}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nqzwja4wc39",
   "metadata": {},
   "source": [
    "### Example: Dynamic Filters + Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yimwuwdryc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Show me Tesla's revenue tables for 2023\"\n",
    "\n",
    "# Extract filters\n",
    "filters = extract_filters(user_query)\n",
    "print(f\"Extracted filters: {filters}\\n\")\n",
    "\n",
    "# Retrieve with content type filtering (text + table)\n",
    "reranked_results = retrieve_with_reranking(\n",
    "    query=user_query,\n",
    "    k=10,\n",
    "    top_k=5,\n",
    "    filters=filters,\n",
    "    content_types=[\"text\", \"table\"]  # Search both text and tables\n",
    ")\n",
    "\n",
    "print(\"Reranked Results:\\n\")\n",
    "for i, (score, doc) in enumerate(reranked_results, 1):\n",
    "    print(f\"{i}. Score: {score:.4f} | Type: {doc.metadata.get('content_type')} | Page: {doc.metadata.get('page')}\")\n",
    "    if doc.metadata.get('content_type') == 'image':\n",
    "        print(f\"   Image: {doc.metadata.get('image_path')}\")\n",
    "    print(f\"   Content: {doc.page_content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432eccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa832d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9befec66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}